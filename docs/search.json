[
  {
    "objectID": "prep-materials/rstudio-orientation.html",
    "href": "prep-materials/rstudio-orientation.html",
    "title": "RStudio Orientation",
    "section": "",
    "text": "Let‚Äôs start working in R! ü•≥\n\n\n\nIntroduction to R\nR is a statistical programming language. Unlike more general-purpose languages, R is optimized for working with data and doing statistics. R was created by Ross Ihaka and Robert Gentleman in 1993 (hence ‚ÄúR‚Äù) and was formally released by the R Core Group in 1997 (a group of 20-ish volunteers who are the only people who can change the base (built-in) functionality of R). If you want to build an independent, standalone graphical interface, or run a web server, R is probably not the ideal language to use (you might want C / Python or PHP / Python, respectively). If you want to vacuum up a bunch of data, fit several regression models, and then compare the models, R is a great option and will be faster than working in a more general-purpose language like C or base Python.\nIn general, R is‚Ä¶\n\nvector-based\n1 indexed (start counting 1, 2, 3, ‚Ä¶)\na scripting language (R code does not have to be compiled before it is run)\n\nOne thing to know about R is that it is open-source. This means that no company owns R (like there is for SAS or Matlab) and that developers cannot charge for the use of their R software. This does not mean that all of your code needs to be public (you can keep your code private), but it is important to be a good open-source citizen by sharing your code publicly when possible (later we will learn about GitHub), contributing to public projects and packages, creating your own packages, and using R for ethical and respectful projects.\n\nüìñ Suggested Reading: Basics of R\n\n\n\n\n\n\nThe History of R\n\n\n\nIf you would like to learn more about the history of R, here is an excellent article written by Roger Peng.\n\n\n\n\nüíª Useful Tutorial: R Programming Basics\n\n\n\n\n\n\nProgramming in R\n\n\n\nThis tutorial gives you an overview of the foundations that make up the R programming language, including:\n\nfunctions and their arguments\naccessing help files\nmaking code comments\nobject types (e.g., vectors, lists, )\ndata types (e.g., numeric, integer, double, character)\nR‚Äôs package system\n\n\n\n\n\n\nIntroduction to RStudio\n\nüìñ Optional Reading: A tour of RStudio\n\nClick Here to download a ‚Äúcheatsheet‚Äù (easy reference page) for navigating the RStudio IDE.\n\n\n\nNavigating RStudio\n\n\n\nThe RStudio window will look something like this.\n\n\n\n\nExploring the Panes\n\nTop-leftTop-rightBottom-leftBottom-right\n\n\nIncludes the text editor. This is where you‚Äôll do most of your work.\n\nThe logo on the script file indicates the file type. When an R file is open, there are Run and Source buttons on the top which allow you to run selected lines of code (Run) or source (run) the entire file. Code line numbers are provided on the left (this is a handy way to see where in the code the errors occur), and you can see line:character numbers at the bottom left. At the bottom right, there is another indicator of what type of file Rstudio thinks this is.\n\n\nIn the top right, you‚Äôll find the environment, history, and connections tabs. The environment tab shows you the objects available in R (variables, data files, etc.), the history tab shows you what code you‚Äôve run recently, and the connections tab is useful for setting up database connections.\n\n\nOn the bottom left is the console. There are also other tabs to give you a terminal (command line) prompt, and a jobs tab to monitor progress of long-running jobs. In this class we‚Äôll primarily use the console tab.\n\n\n\nOn the bottom right, there are a set of tabs:\n\nfiles (to give you an idea of where you are working, and what files are present),\n\n\n\nplots (which will be self-explanatory),\npackages (which extensions to R are installed and loaded),\n\n\n\nthe help tab (where documentation will show up), and\n\n\n\nthe viewer window, which is used for interactive graphics or previewing HTML documents.\n\n\n\n\n\n\n\nInstalling Packages\n\nüìΩÔ∏è Recommended Video: Installing R Packages (4 minutes)\n\n\nInstall / Update the ggformula, mosaic, and tidyverse\n\n\n\n\n\n\nWorking on the R Server\n\n\n\nIf you are using the R Server (Cal ICOR Hub) these packages are already installed and do not need to be installed again.\n\n\nNow that you have the hang of working in RStudio, let‚Äôs install / update the packages we will use in the course. In this course, we will make heavy use of the tidyverse suite of packages.\nIf you have not used the tidyverse before, type the following into your console or use the drop down menu in the Packages tab (as seen in the video above):\n\ninstall.packages(\"tidyverse\")\n\nIf you have used the tidyverse before, you only need to update packages.\nType the following into your console:\n\nlibrary(tidyverse)\ntidyverse_update()\n\nThen follow the instructions that print out to update a few of your tidyverse packages.\nIn addition, install the packages we used throughout our course.\n\ninstall.packages(c(\"ggformula\", \"mosaic\"))",
    "crumbs": [
      "Getting Started with R",
      "RStudio Orientation"
    ]
  },
  {
    "objectID": "prep-materials/install-r.html",
    "href": "prep-materials/install-r.html",
    "title": "Optional: Installing R and RStudio",
    "section": "",
    "text": "For our class we do not need to install R and RStudio as we will be using the CSUMB Cal ICOR Hub R Server.\nAfter you leave CSUMB, though, you will want to be able to access R and RStudio on your own computer. We are going to learn about / refresh our memory on R and RStudio to make sure you have a local installations of both R and RStudio on your computer.",
    "crumbs": [
      "Getting Started with R",
      "Optional: Install R and RStudio"
    ]
  },
  {
    "objectID": "prep-materials/install-r.html#updating-your-version-of-r",
    "href": "prep-materials/install-r.html#updating-your-version-of-r",
    "title": "Optional: Installing R and RStudio",
    "section": "Updating Your Version of R",
    "text": "Updating Your Version of R\nIf you already have R downloaded, you need to confirm that you have the most up to date version of R. Do not ignore these instructions. If you neglect to update your version of R, you may find that updating a package will make it so your code will not run.\n\nStep 1: Open RStudio\nStep 2: At the top of the the Console it will say what version of R you are using\n\n\nIf the version is not 4.5.1 (like the image above), you need to update your version of R! The simplest way to do this is to follow the instructions below to install R.",
    "crumbs": [
      "Getting Started with R",
      "Optional: Install R and RStudio"
    ]
  },
  {
    "objectID": "prep-materials/install-r.html#installing-r",
    "href": "prep-materials/install-r.html#installing-r",
    "title": "Optional: Installing R and RStudio",
    "section": "Installing R",
    "text": "Installing R\nDownload and install R by going to https://cloud.r-project.org/. Here, you will find three options for installing R‚Äîclick on the option for your computer‚Äôs operating system.\n\nüìΩÔ∏è Useful Video: Installing R and RStudio - Windows\n\n\nüìΩÔ∏è Useful Video: Installing R and RStudio - Mac\n\n\nIf you are a Windows user:\n\nClick on ‚ÄúDownload R for Windows‚Äù\nClick on ‚Äúbase‚Äù\nClick on the Download link.\nWhen you open the execution file (.exe) you will be prompted with a variety of questions about installing R. Feel free to use the default features / settings that come with R (continue to click ‚ÄúOk‚Äù until the download starts).\n\n\n\n\n\n\n\nMultiple Versions of R\n\n\n\nBeware that if you had a previous version of R downloaded on your PC, that old version will not be deleted when you download the most recent version of R. We do not want to have two versions of R installed, as your computer can get confused what version of R to use. So, you need to remove the old version of R.\nTo do this you need to:\n\nNavigate to your computer‚Äôs settings\nClick on the ‚ÄúApps‚Äù option on the left-hand panel\nSearch for or scroll down to R\nFind the older version of R\n\n\n\nClick on the ... on the right side\nSelect ‚ÄúUninstall‚Äù\n\n\n\n\n\n\nIf you are macOS user:\n\nClick on ‚ÄúDownload R for (Mac) OS X‚Äù\nUnder ‚ÄúLatest release:‚Äù click on R-X.X.X.pkg, where R-X.X.X is the version number. For example, the latest version of R as of October 31, 2024 was R-4.4.2 (Pile of Leaves).\nWhen installing, use the default features / settings that come with R (click Ok until the download starts).\n\n\n\n\n\n\n\nTroubleshooting for Macs\n\n\n\nFirst, identify which version of OSx you are running. How-to\nNext, find out which version of R your computer can run. Link\nIf this version is 3.6 or later, download the latest version that your computer can handle.\nIf this version is 3.4 or earlier, you‚Äôre going to run in to some trouble. I recommend updating your version of OSx, if you are willing. If you can‚Äôt, then you can use Posit Cloud to run R and RStudio on a free server. However, I recommend strongly against this option; your files will not be saved indefinitely, you will have limited hours to complete your work, your computing power will be limited, and you will need an internet connection at all times to do your work.\n\n\n\n\nIf you are a Linux user:\nClick on ‚ÄúDownload R for Linux‚Äù and choose your distribution for more information on installing R for your setup.",
    "crumbs": [
      "Getting Started with R",
      "Optional: Install R and RStudio"
    ]
  },
  {
    "objectID": "prep-materials/install-r.html#updating-your-version-of-rstudio",
    "href": "prep-materials/install-r.html#updating-your-version-of-rstudio",
    "title": "Optional: Installing R and RStudio",
    "section": "Updating Your Version of RStudio",
    "text": "Updating Your Version of RStudio\nIf you already have RStudio, you need to double check if you have the most recent version. You will not have access to the newest features for Quarto documents unless you have the most recent version of RStudio.\n\nStep 1: Open RStudio\nStep 2: Click on ‚ÄúHelp‚Äù in the upper menu\nStep 3: Click on ‚ÄúCheck for Updates‚Äù\n\nIf there are no updates to RStudio since you installed it, you are good to go! If you need to update RStudio, you will be sent to Posit (the parent company) to download the most recent version of RStudio desktop.",
    "crumbs": [
      "Getting Started with R",
      "Optional: Install R and RStudio"
    ]
  },
  {
    "objectID": "prep-materials/install-r.html#installing-rstudio",
    "href": "prep-materials/install-r.html#installing-rstudio",
    "title": "Optional: Installing R and RStudio",
    "section": "Installing RStudio",
    "text": "Installing RStudio\nDownloading the most recent version of RStudio works the same way regardless of whether you‚Äôve never downloaded RStudio before or if you just need to update your version of RStudio.\nWhen you navigate to the RStudio download page (https://rstudio.com/products/rstudio/download/), the website should automatically detect your computer‚Äôs operating system. So, you should be able to simply click the blue ‚ÄúDownload RStudio Desktop for [insert operating system here]‚Äù button.\nClicking the button will begin installing RStudio. Once the download has completed, you will need to open the application file (on a Mac this is a .dmg file, on Windows this is an exe file).",
    "crumbs": [
      "Getting Started with R",
      "Optional: Install R and RStudio"
    ]
  },
  {
    "objectID": "lab-8-primer/lab-8-anova-primer.html#getting-started",
    "href": "lab-8-primer/lab-8-anova-primer.html#getting-started",
    "title": "Lab 8: ANOVA",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 8 Primer"
    ]
  },
  {
    "objectID": "lab-8-primer/lab-8-anova-primer.html#exercise-and-brain-size",
    "href": "lab-8-primer/lab-8-anova-primer.html#exercise-and-brain-size",
    "title": "Lab 8: ANOVA",
    "section": "2 Exercise and Brain Size",
    "text": "2 Exercise and Brain Size\nIn 2020, the Center for Disease Control (CDC) estimated that as many as 5.8 million Americans were living with Alzheimer‚Äôs. While there are several diseases that can cause dementia, Alzheimer‚Äôs disease is the most common type of dementia. There are many risk factors that contribute to dementia that can be controlled, like diet, exercise, smoking status & alcohol consumption. Yet other risk factors like genetics and aging can‚Äôt be controlled. Brain size typically starts to shrink in your 30s and 40s with an increase in shrinkage rate at age 60. Therefore, any intervention that can protect against brain shrinkage could help to protect the elderly against dementia and Alzheimer‚Äôs disease. Researchers in China recently investigated whether different kinds of exercise/activity might help to prevent brain shrinkage or perhaps even lead to an increase in brain volume (Mortimer et al., 2012).\nThe researchers randomly assigned elderly adult volunteers into four activity groups: tai chi, walking, social interaction, and no intervention. Except for the group with no intervention, each group met for about an hour three times a week for 40 weeks to participate in their assigned activity. Each participant had their brains imaged using magnetic resonance imaging (MRI) to determine brain volume before the study began and again at its end. The researchers measured the percentage change in brain volume in each participant‚Äôs brain during that time. If a person‚Äôs brain volume increased, then this percentage change was positive; if brain volume decreased, then this percentage change was negative.\n\n\n\n\n\n\n\n\n\n2.1 Identify Variables and Types\nFor each variable, identify whether it is the explanatory or response variable in our analysis, and the type of variable.\nActivity:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical - Ordinal\n\n\nCategorical - Nominal\n\n\nNumeric - Discrete\n\n\nNumeric - Continuous\n\n\n\n\n\n\n\n\nChange in brain volume (%)\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical - Ordinal\n\n\nCategorical - Nominal\n\n\nNumeric - Discrete\n\n\nNumeric - Continuous\n\n\n\n\n\n\n\n\n\n\n2.2 Identify the study type of this study.\nBe sure you are able to provide a full justification.\n\n\n\n\nExperiment\n\n\nObservational\n\n\n\n\n\n\n\n\n\n\n2.3 Exploratory Data Analysis\nConduct Exploratory Data Analysis (EDA). Modify the code below to calculate any summary statistics and produce a graphic.\n\n\n\n\n\n\n\n\n\n\n\ndf_stats(brain_change ~ treatment, data = brain)\ndf_stats(brain_change ~ treatment, data = brain)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngf_boxplot(brain_change ~ treatment, data = brain,\n           ylab = \"Percentage Change in Brain Volume\",\n           xlab = \"Activity Group for 40 Weeks\")\ngf_boxplot(brain_change ~ treatment, data = brain,\n           ylab = \"Percentage Change in Brain Volume\",\n           xlab = \"Activity Group for 40 Weeks\")\n\n\n\n\n\n\n\n\n2.4 Identify the hypotheses for this study.\nNote, these options are generic and not complete. Be sure you are able to complete them in context, symbolically and verbally for your labs.\n\n\n\n\nThe difference of true means is 0\n\n\nAll true means are equal\n\n\nAll true means are equal to 0\n\n\nAll true means are different\n\n\nAt least one true mean is different\n\n\nMore than one true mean is different\n\n\n\n\n\n\n\n\n\n\n2.5 Modify the code below to create the ANOVA model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbrain_aov &lt;- aov(brain_change ~ factor(treatment), data = brain)\n\n\n\n\n\n\n2.6 Evaluate Conditions\nConduct an appropriate testing of the conditions to trust an ANOVA analysis.\n\n2.6.1 Normality of Residuals\n\n\n\n\n\n\n\n\n\n\n\nplot(brain_aov, 2)\nplot(brain_aov, 2)\n\n\n\n\n\n\n\nAre the conditions for normality/sufficient sample size met in order to use the F distribution as a model for the null distribution of the F-ratio?\n\n\n\n\nMet\n\n\nNot Met\n\n\n\n\n\n\n\n\n\n\n\n2.6.2 Constant Variance (Homogeneity) of Populations\n\n\n\n\n\n\n\n\n\n\n\nplot(brain_aov, 1, add.smooth = FALSE)\nplot(brain_aov, 1, add.smooth = FALSE)\n\n\n\n\n\n\n\nAre the conditions for constant variance across populations met in order to use the F distribution as a model for the null distribution of the F-ratio?\n\n\n\n\nMet\n\n\nNot Met\n\n\n\n\n\n\n\n\n\n\n\n\n2.7 ANOVA Table\nComplete the code below to print out an anova table for your analysis. Fill in the values of the appropriate statistics. Round to 4 decimal places\n\n\n\n\n\n\n\n\n\n\n\nanova(brain_aov)\nanova(brain_aov)\n\n\n\n\n\n\n\n2.7.1 \\(df_e\\):\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.2 \\(df_t\\):\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.3 MSE:\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.4 MST:\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.5 F:\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.6 p-value:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.8 Evaluate the strength of your evidence from the hypothesis test, using a 0.05 significance level.\n\n\n\n\nvery strong\n\n\nstrong\n\n\nmoderate\n\n\nlittle\n\n\nvery little\n\n\n\n\n\n\n\n\n\n\n2.9 Conduct a Tukey test by modifying the code below.\n\n\n\n\n\n\n\n\n\n\n\nTukeyHSD(brain_aov)\nTukeyHSD(brain_aov)\n\n\n\n\n\n\n\n\n2.10 Identify which pairs are different (at least moderate evidence against the null).\n\n\n\n\nSocial-None\n\n\nTaiChi-None\n\n\nWalking-None\n\n\nTaiChi-Social\n\n\nWalking-Social\n\n\nWalking-TaiChi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Post-Hoc and ANOVA Tests ‚ÄúDisagree‚Äù\n\n\n\n\n\nYou might be wondering why we found evidence against the null for the ANOVA, but only ‚Äúsome‚Äù evidence against the null for one pairwise comparison from the Tukey Test. There are several possible reasons this could happen.\n\nConditions are Not Met: While not applicable to our situation, this could be a reason the ANOVA and Post-Hoc Tests do not match, especially if the constant variance condition is not met.\n\nUnder-powered Study Design: For all the comparisons we are doing we are actually using a ‚Äòsmaller‚Äô significance level than the \\(\\alpha = 0.05\\) experimentwise error rate. Since decreasing the significance level also decreases the power, it is possible we do not have big enough group sizes to detect the effect size of interest in our study.\n\nUnbalanced Design: Tukey Tests in particular are sensitive to unbalanced designs, i.e.¬†each group has a different number of replicates, which could explain the weak evidence again the null for only one group for our study, which is unbalanced.\n\nSo what is a statistician to do? There are post-hoc comparisons that might be better suited for this study than the Tukey HSD Test. You can learn more about those methods in STAT 325: Experimental Design and Analysis.\n\n\n\n\n\n2.11 Which of the following conclusions about the study are true?\n\n\n\n\nWe can generalize our results because our sample size is large\n\n\nWe can generalize our results because we have representative sample\n\n\nWe cannot generalize our results because we have a biased sample\n\n\nWe can determine causality because we eliminated confounding variables\n\n\nWe cannot determine causality because we didn't account for age, weight, etc.\n\n\nWe cannot determine causality because we have a biased sample\n\n\nWe can trust our results because our sample size is large\n\n\nWe cannot trust our results because we do not have a random sample\n\n\nWe can trust our results because we met the normality, equal variance, and independence conditions\n\n\nWe cannot trust our results because we did not have significant results",
    "crumbs": [
      "Lab Primers",
      "Lab 8 Primer"
    ]
  },
  {
    "objectID": "lab-6-primer/lab-6-two-groups-primer.html#getting-started",
    "href": "lab-6-primer/lab-6-two-groups-primer.html#getting-started",
    "title": "Lab 6: Hypothesis Testing - Two Independent Groups",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\n\n\n\n\n\n\n\n\n\n\n\n\nRevisit Lab 5 Primer\n\n\n\nThe examples used in the Lab 6 Primer are continuations from the Lab 5 Primer. We encourage you to go back and review your previous answers and code to help you with your lab.",
    "crumbs": [
      "Lab Primers",
      "Lab 6 Primer"
    ]
  },
  {
    "objectID": "lab-6-primer/lab-6-two-groups-primer.html#sex-bias-in-professor-ratings",
    "href": "lab-6-primer/lab-6-two-groups-primer.html#sex-bias-in-professor-ratings",
    "title": "Lab 6: Hypothesis Testing - Two Independent Groups",
    "section": "2 Sex Bias in Professor Ratings",
    "text": "2 Sex Bias in Professor Ratings\nSex bias stems from a perceived mismatch from an expected role or characteristics based on sex. Studies have shown that men and women have unconscious sex biases against women in traditionally male-dominated fields (such as the sciences) or characteristics (such as leadership qualities). These biases often cause equally qualified women to be seen as less likable or less qualified than the men. (These links are to descriptions of two well-known studies, but there are plenty of other good resources).\nResearchers are interested if this sex bias exists in traditionally female-dominated jobs as well, such as teaching. Students are asked to watch a video of an animated classroom and rate the professor. Each student is randomly assigned to either of two animations; the videos are exactly the same except for the sex of the professor drawn. You have been asked to analyze the data for the researchers to determine if the female-identifying professor is rated more poorly, on a 1 to 7 scale (with 7 being the best), than the male-identifying professor.\nRun the following code chunk to read in the data and view the variable names and first 6 rows of the data.\n\n\n\n\n\n\n\n\n\n2.1 Identify the Parameters\n\nIdentify the study design of this study.\nBe sure you are able to provide a full justification. This is review from the Lab 5 Primer.\n\n\n\n\nIndependent Two Sample\n\n\nMatched Pair Sample\n\n\n\n\n\n\n\n\n\n\nIdentify the parameter(s) that would be of interest based on the study design.\n\n\n\n\nŒº‚Çì‚Çì = true mean rating for female professor videos\n\n\nŒº‚Çì·µß = true mean rating for male professor videos\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß = true mean of the differences of the ratings between male and female professor videos\n\n\nxÃÑ‚Çì‚Çì\n = mean rating for our sample of female professor videos\n\n\nxÃÑ‚Çì·µß\n = mean rating for our sample of male professor videos\n\n\nxÃÑ‚Çì‚Çì‚Çã‚Çì·µß = mean difference of the ratings between sample of male and female professor videos\n\n\n\n\n\n\n\n\n\n\nIdentify the null hypothesis that would be of interest based on the study design.\nThe researchers want to determine if the female-identifying professor is rated more poorly, on a 1 to 7 scale (with 7 being the best), than the male-identifying professor. (Female - Male)\n\n\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß = 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß &lt; 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß &gt; 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß ‚â† 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß = 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß &lt; 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß &gt; 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß ‚â† 0\n\n\n\n\n\n\n\n\n\n\nIdentify the alternative hypothesis that would be of interest based on the study design.\nThe researchers want to determine if the female-identifying professor is rated more poorly, on a 1 to 7 scale (with 7 being the best), than the male-identifying professor.\n\n\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß = 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß &lt; 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß &gt; 0\n\n\nŒº‚Çì‚Çì - Œº‚Çì·µß ‚â† 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß = 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß &lt; 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß &gt; 0\n\n\nŒº‚Çì‚Çì‚Çã‚Çì·µß ‚â† 0\n\n\n\n\n\n\n\n\n\n\n\n2.2 Exploratory Data Analysis\nRecall from the Lab 5 Primer, we calculated the following summary statistics and data visualizations.\n\n2.2.1 Summary Statistics\n\ndf_stats(Rating ~ Sex, data = bias) \n\n  response    Sex min   Q1 median   Q3 max     mean       sd  n missing\n1   Rating Female   0 2.25      4 5.00   6 3.647059 1.554706 34       0\n2   Rating   Male   3 4.00      5 5.75   7 4.764706 1.016793 34       0\n\n\n\n\n2.2.2 Data Visualization\n\ngf_boxplot(Rating ~ Sex, data = bias, \n        ylab = \"Rating of Professor in Video (Scale 1-7)\", \n        xlab = \"Sex of the Professor in Video\") \n\n\n\n\n\n\n\n\n\n\n2.2.3 QQ Plot\n\ngf_qq(~Rating | Sex, data = bias,\n      xlab = \"Theoretical Z-Scores\",\n      ylab = \"Rating of Professor in Video\") |&gt; \n  gf_qqline()\n\n\n\n\n\n\n\n\n\nBased on the provided information, do we meet the necessary conditions to conduct inference using the t-distribution (e.g.¬†confidence interval, hypothesis test)?\n\nRemember to check the conditions of sufficient sample size and normality together.\n\nThe sufficient sample size depends on whether our sample indicates the population may or may not be normality distributed (now evaluated using the QQ Plot).\n\nProvide a statement, based on the condition check, to determine if we can or cannot use the t-distribution as a model for null distribution or sampling distribution of our test/sample statistic.\n\n\n\n\n\n2.3 Calculating the Test Statistic and P-Value\nWe will practice code for both a ‚Äúby-hand‚Äù calculation and using t.test() (which is what we will be using from in general).\nFor the ‚Äúby-hand‚Äù calculation, we will need to split the dataset into two parts, one dataset for the male professor video ratings and one for the female professor video ratings.\nWe can use the function filter() to extract out specific rows associated with a specific variable value. Notice that we use double equal signs == to indicate equivalence with a particular value, and since our variable is a categorical (character), we put the value in quotes.\n\n\n\n\n\n\n\n\n\nCalculate the summary statistics for each sample. Modify the code below to calculate the summary statistics for each group.\nHere are the necessary summary statistics for the Female professor video Ratings. We will save them for later use. To get them to both save and print, we can add parentheses around each statement\n\n\n\n\n\n\n\n\n\n\n\n2.4 Calculating a t-Test Statistic and p-Value\nNow that we have the necessary summary statistics saved, we can calculate both our test statistic (t) and our p-value. Recall the t-statistic for an independent two-sample test is\n\\[t_0 = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\]\nRecall that we are looking at Female Ratings - Male Ratings. Fill in the blanks below using the saved object names (e.g.¬†mean_f, var_m) from above.\n\n\n\n\n\n\n\n\nYou should get \\(se = 0.3185897\\) and \\(t = -3.508107\\).\nNow, calculate the p-value using the pt() function. Consider the direction of the alternative hypothesis.\n\n\n\n\n\n\n\n\n\n\n\npt(t, df = n_f - 1)\npt(t, df = n_f - 1)\n\n\n\n\n\n\nNow, let‚Äôs calculate the test statistic and p-value using the t.test() function. Consider the direction of the alternative hypothesis. Recall you have three choices for the alternative.\n\n\"two.sided\"\n\n\"greater\"\n\n\"less\"\n\n\n\n\n\n\n\n\n\n\n\n\nt.test(Rating ~ Sex, data = bias, mu = 0, alternative = \"less\")\nt.test(Rating ~ Sex, data = bias, mu = 0, alternative = \"less\")\n\n\n\n\n\n\n\n2.4.1 Switching the Direction of the Difference\nUltimately, it is up to the researcher to choose the direction of the calculated difference. If we wanted to switch our difference and have Male Ratings - Female Ratings, we would have to tell R to change the ordering of our variable using the mutate() function, since R defaults to reading our groups alphabetically and in the t.test() code would default to Female Ratings - Male Ratings (since F comes before M).\nHere is the code to reorder the variable levels so \"Male\" is read first:\n\n\n\n\n\n\n\n\nNow, rerun the t.test() code, but using bias_reorder. What do you have to change to make the test equivalent?\n\n\n\n\n\n\n\n\n\n\n\nt.test(Rating ~ Sex, data = bias_reorder, mu = 0, alternative = \"greater\")\nt.test(Rating ~ Sex, data = bias_reorder, mu = 0, alternative = \"greater\")\n\n\n\n\n\n\n\n\n\n2.5 Interpreting and Evaluating the p-Value\nUsing the calculate p-value from the t.test() function to answer the following questions.\n\nReorder to provide the appropriate interpretation of the p-value.\n\n\n\n\n\n\nThere is a probability of\n\n\n\n‚áÖ\n\n\n\nof t = -3.5081\n\n\n\n‚áÖ\n\n\n\nthat there is no difference between the true mean ratings for male and female professor videos\n\n\n\n‚áÖ\n\n\n\n0.0004447\n\n\n\n‚áÖ\n\n\n\nassuming the null hypothesis is true\n\n\n\n‚áÖ\n\n\n\nof observing our test statistic\n\n\n\n‚áÖ\n\n\n\nor less\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluate the strength of evidence against the null hypothesis, using a significance level of \\(\\alpha = 0.05\\)\n\n\n\n\nno evidence\n\n\nlittle evidence\n\n\nsome evidence\n\n\nmoderate evidence\n\n\nstrong evidence\n\n\nvery strong evidence\n\n\n\n\n\n\n\n\n\n\n\n\n\nFull Evaluation of Strength of Evidence\n\n\n\n\n\nRemember we have specific details to include in a full evaluation of the strength of evidence.\nWe have {very strong/strong/moderate/some/little} evidence against the null hypothesis (in favor of the alternative hypothesis) that {context of indicated hypothesis} (t = {xxx}, df = {xxx}, p-value = {xxx}).\n\n\n\n\n\n\nWhich of the following statements are true based on the p-value?\n\n\n\n\nthere is a very small probability the null is true\n\n\nour data/test statistic is very unlikely to be observed if the null is true\n\n\nthere is a very small probability the alternative is true\n\n\nthere is a very large probability the alternative is true\n\n\nthere is a very small probability of finding evidence against the null\n\n\n\n\n\n\n\n\n\n\n\n2.6 Calculating a Confidence Interval for the Difference of Two Means\nIn order to calculate the confidence interval for the difference of two population means, it takes on the same structure as a confidence interval for one population mean.\n\\[point \\ estimate \\pm (critical \\ value)*(standard\\ error)\\]\nor\n\\[\\bar{x}_1 - \\bar{x}_2 \\ \\pm \\ t^*{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\]\nWe can find our \\(t^*\\) critical value the same way we found it for previous confidence intervals.\n\n\n\n\n\n\n\n\nOur point estimate is \\(\\bar{x}_1 - \\bar{x}_2\\)\n\n\n\n\n\n\n\n\nand finally we can calculate the lower bound (lb) and upper bound (ub) for our confidence interval.\n\n\n\n\n\n\n\n\nOf course, the ‚Äúby-hand‚Äù method is tedious when we can just use t.test() to calculate our confidence interval. Fill in the blanks below to calculate the 95% confidence interval for the difference between the two means.\n\n\n\n\n\n\n\n\n\n\n\nt.test(Rating ~ Sex, data = bias, conf.level = 0.95)$conf.int\nt.test(Rating ~ Sex, data = bias, conf.level = 0.95)$conf.int\n\n\n\n\n\n\n\n\nProvide an interpretation of the confidence interval by reordering the phrases below.\n\n\n\n\n\n\nwe are 95% confident that\n\n\n\n‚áÖ\n\n\n\nthe difference between\n\n\n\n‚áÖ\n\n\n\nBased on the sample\n\n\n\n‚áÖ\n\n\n\nand\n\n\n\n‚áÖ\n\n\n\nthe true mean rating of female professor videos\n\n\n\n‚áÖ\n\n\n\nwithin the interval\n\n\n\n‚áÖ\n\n\n\nthe true mean rating of male professor videos\n\n\n\n‚áÖ\n\n\n\nis a single value\n\n\n\n‚áÖ\n\n\n\nLB and UB\n\n\n\n\n\n\n\n\n\n\n\n\nWhich of the following would be plausible estimates for the difference between two true mean ratings?\n\n\n\n\n0\n\n\n-1\n\n\n1\n\n\n-1.5\n\n\n-0.5\n\n\n0.5\n\n\n1.5\n\n\n-2\n\n\n2\n\n\n\n\n\n\n\n\n\n\nWhat can we conclude about the study?\n\n\n\n\nwe can infer that the sex of the professor in the video causes ratings to be different for the videos\n\n\nwe cannot infer that the sex of the professor in the video causes ratings to be different for the videos\n\n\nthere is evidence the ratings for female professors are lower than for male professors in the videos\n\n\nthere is no evidence the ratings for female professors are lower than for male professors in the videos",
    "crumbs": [
      "Lab Primers",
      "Lab 6 Primer"
    ]
  },
  {
    "objectID": "lab-4-primer/lab-4-confidence-primer.html#getting-started",
    "href": "lab-4-primer/lab-4-confidence-primer.html#getting-started",
    "title": "Lab 4: Estimation of a Population Mean Primer",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 4 Primer"
    ]
  },
  {
    "objectID": "lab-4-primer/lab-4-confidence-primer.html#honeybee-population-decline",
    "href": "lab-4-primer/lab-4-confidence-primer.html#honeybee-population-decline",
    "title": "Lab 4: Estimation of a Population Mean Primer",
    "section": "2 Honeybee Population Decline",
    "text": "2 Honeybee Population Decline\nMany ecologists and citizens are concerned that the population of honeybees is declining. Honeybees perform an essential ecosystem service of pollinating crops in California and across the United States. Ecologists are concerned about the use of pesticides and the rise of colony collapse disorder.\nThe U.S. Department of Agriculture (USDA) collects information about the number of honeybee colonies in the United States. Researchers at the USDA reached out to registered apiarists (bee keepers) in each state on a week that was selected by random number generation, starting in 2000. They record the total number of honeybee colonies reported in each selected week.\nThe dataset honey-bee-colonies-2020.csv has the data recorded in the variable Colonies, which records the number of honeybee colonies, in thousands.\nModify the function below to read in the dataset we will use in the example and store it as the object bee.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint for Importing Data\n\n\n\n\n\nRemember to use read_csv() to import the data. To hide the information it outputs about the variables and their types, add show_col_types = FALSE.",
    "crumbs": [
      "Lab Primers",
      "Lab 4 Primer"
    ]
  },
  {
    "objectID": "lab-4-primer/lab-4-confidence-primer.html#study-components",
    "href": "lab-4-primer/lab-4-confidence-primer.html#study-components",
    "title": "Lab 4: Estimation of a Population Mean Primer",
    "section": "3 Study Components",
    "text": "3 Study Components\nHere are a few rows of the data:\n\n\n\n\n\n\n\n\nHoney Bee Colonies in the US\n\n\nYear\nColonies\n\n\n\n\n2004\n2556\n\n\n2006\n2393\n\n\n2001\n2506\n\n\n2019\n2812\n\n\n2005\n2410\n\n\n2008\n2301\n\n\n2000\n2634\n\n\n2012\n2539\n\n\n2014\n2740\n\n\n2016\n2775\n\n\n\n\n\n\n\nBefore we work on creating and evaluating a confidence interval for these data, it is helpful to make sure we understand the data and how it is structured. Can you identify\n\nthe case?\n\nthe population?\n\nthe variable of interest and its type?\n\nthe sampling design?\n\nOnce you think you have identified the components, check your understanding below.\n\n3.0.1 Which of the following is the variable of interest and its type in this research question?\n\n\n\n\nsize of honeybee colony\n\n\nnumber of honeybee colonies\n\n\nnumber of bees in a colony\n\n\naverage number of colonies per keeper\n\n\naverage number of honeybee colonies in the U.S.\n\n\ncategorical nominal\n\n\ncategorical ordinal\n\n\nnumeric discrete\n\n\nnumeric continuous\n\n\n\n\n\n\n\n\n\nClick Here for Hint about Variable\n\n\n\n\n\n\nClick Here for Hint about Variable Type\n\n\n\n\n\n\n3.0.2 Which of the following is the case in this dataset?\n\n\n\n\na honeybee\n\n\nall honeybees\n\n\nall honeybee colonies\n\n\na honeybee colony\n\n\nall honeybee colonies in the U.S.\n\n\na honeybee colony in the U.S.\n\n\na year\n\n\na week\n\n\nall weeks since 2000\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n\n3.0.3 Which of the following is the population of interest for this research question?\n\n\n\n\na honeybee\n\n\nall honeybees\n\n\nall honeybee colonies\n\n\na honeybee colony\n\n\nall honeybee colonies in the U.S.\n\n\na honeybee colony in the U.S.\n\n\na year\n\n\na week\n\n\nall weeks since 2000\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n\n3.0.4 Which of the following could be the sample for this study?\n\n\n\n\nall honeybee colonies\n\n\n20 honeybee colonies\n\n\nall honeybee colonies in the U.S.\n\n\n20 honeybee colonies in the U.S.\n\n\n20 weeks since 2000\n\n\nmean number of honeybee colonies in the US\n\n\na week\n\n\nall weeks since 2000\n\n\nmean number of weeks since 2000\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n\n3.0.5 What is the sampling method used by the researchers?\n\n\n\n\nStratified Random Sample\n\n\nVolunteer Sample\n\n\nSimple Random Sample\n\n\nConvenience Sample\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n\n3.0.6 If we were to calculate the average size of a honeybee colony in the U.S. from 50 selected colonies, that would be an example of a‚Ä¶\n\n\n\n\nsample\nstatistic\nparameter\npopulation\n\n\n\n\n\n\n\n\n\nClick Here for Hint 1\n\n\n\n\n\n\nClick Here for Hint 2\n\n\n\n\n\n\n\n3.1 Single Numeric Variable Graphics\n\n3.1.1 Histogram\nTo create a histogram of a single numeric variable, we use the following structure:\n\ngf_histogram(~ x, data = mydata)\n\nwhere x is the name of the variable you wish to graph that is stored in the dataset named mydata.\nRecall that we already loaded in our data on the prior page and named it bee. We want to graph the variable Colonies that occurs in the bee dataset.\n\n\n\n\n\n\n\n\n\nFill in the x blank with the name of the variable. Fill in the mydata blank with the dataset object name.\n\n\ngf_histogram(~Colonies, data = bee)\ngf_histogram(~Colonies, data = bee)\n\n\n\n\n\n\nThat histogram is quite hard to read, so we can add some arguments to the basic code to help us visualize the data better. Recall you can use the following arguments:\n\nxlab = ‚Äú___‚Äù : label the x-axis\n\nylab = ‚Äú___‚Äù : label the y-axis\n\nboundary = ## : set the number where bins begin\n\ncolor = ‚Äú___‚Äù : add an outline around the bins to see them better; fill in this blank with a color name\n\nbinwidth = ## : adjust the width of bins\n\nAdjust the arguments in the code chunk below until your graphic looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAny multiple of the binwidth will work for the boundary entry, but 0 is the easiest to use most of the time. Your x-axis label should include the full variable, units, and the population. The y-axis could be labeled the frequency of the case, in context, if you like. In this scenario, that would be ‚ÄúFrequency of Weeks.‚Äù If you need to review the variables, population or case, review in the prior section.\n\n\ngf_histogram(~Colonies, data = bee,\n             xlab = \"Number of U.S. Honeybee Colonies (in thousands) in weeks since 2000 \", \n             ylab = \"Frequency\",\n             binwidth = 50, \n             boundary = 0, \n             color = \"black\")\ngf_histogram(~Colonies, data = bee,\n             xlab = \"Number of U.S. Honeybee Colonies (in thousands) in weeks since 2000 \", \n             ylab = \"Frequency\",\n             binwidth = 50, \n             boundary = 0, \n             color = \"black\")\n\n\n\n\n\n\n\n\n3.1.2 Boxplot\nTo create a boxplot of a single numeric variable, we use the following structure:\n\ngf_boxplot(~ x, data = mydata)\n\nwhere x is the name of the variable you wish to graph that is stored in the dataset named mydata.\nRecall that we already loaded in our data on the prior page and named it bee. We want to graph the variable Colonies that occurs in the bee dataset.\n\n\n\n\n\n\n\n\n\nFill in the x blank with the name of the variable. Fill in the mydata blank with the dataset object name. The function to make a boxplot is gf_boxplot.\n\n\ngf_boxplot(~Colonies, data = bee)\ngf_boxplot(~Colonies, data = bee)\n\n\n\n\n\n\nWe only need a little adjustment to the boxplot because it is based on statistics. We can use the following following arguments:\n\nxlab = ‚Äú___‚Äù : label the x-axis\n\nylab = ‚Äú___‚Äù : label the y-axis\n\n\n\n3.1.3 Is there a y-axis in a single numeric variable boxplot?\n\n\n\n\nno\n\n\nyes\n\n\n\n\n\n\n\nNow re-create your boxplot with the appropriate axis label(s).\n\n\n\n\n\n\n\n\n\nSince the single numeric variable is horizontal, the x-axis is the variable being graphed and should be labeled. The y-axis is meaningless and should not be. Your x-axis label should include the full variable, units, and the population. If you need to review the variables, population or case, review in the prior section.\n\n\ngf_boxplot(~Colonies, data = bee,\n           xlab = \"Number of U.S. Honeybee Colonies (in thousands) in weeks since 2000 \")\ngf_boxplot(~Colonies, data = bee,\n           xlab = \"Number of U.S. Honeybee Colonies (in thousands) in weeks since 2000 \")\n\n\n\n\n\n\n\n\n3.1.4 What is the shape and modality of these data?\n\n\n\n\n\nsymmetric\n\n\nright skewed\n\n\nslightly left skewed\n\n\nunimodal\n\n\nbimodal\n\n\nmultimodal\n\n\nunable to determine shape\n\n\nunable to determine modality\n\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n3.1.5 Based on the shape, the mean should be _______ the median.\n\n\n\n\n\ngreater than\nless than\nequivalent to\n\n\n\n\n\n\n\n\n\n\n3.2 Single Numeric Variable Summary Statistics\nWe can calculate the single numeric variable summary statistics using the following structure:\n\ngoal(~x, data = mydata)\n\nwhere x is the name of the numeric variable stored inside the dataframe object named mydata. goal stands in for any of the summary statistic functions we might use, such as:\n\nmean\nmedian\nsd\nIQR\nquantile\ndf_stats\n\nAll of these functions use the exact same structure (and the same basic structure as your graphics) for single numeric variables.\nUse the code chunk below to calculate some summary statistics, such as the following:\n\n\n  response  min   Q1 median      Q3  max   mean       sd  n missing\n1 Colonies 2301 2504 2616.5 2672.75 2812 2591.3 141.1066 20       0\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 Check Your Understanding\nYou may need to refer to the graphics or summary statistics you calculated above to answer these questions.\n\n3.3.1 How many cases have between 2301 and 2504 thousand colonies?\n\n\n\n\nEnter your answer below\n\n\n\n\n\n\n\n\n\n\nClick Here for Hint 1\n\n\n\n\n\n\nClick Here for Hint 2\n\n\n\n\n\n\n3.3.2 What is the name for the distance between 2504 and 2672.75 thousand colonies on the boxplot?\n\n\n\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n3.3.3 There are more cases that have values between 2301 and 2504 thousand colonies than cases that have values between 2672.75 and 2812 thousand colonies.\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n3.3.4 The cases that have values between 2301 and 2504 thousand colonies are more dispersed then the cases that have values between 2672.75 and 2812 thousand colonies.\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n3.3.5 We could have determined the modality of the distribution without making a histogram (i.e.¬†with just statistics or the boxplot).\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\n\n\n\nClick Here for Hint\n\n\n\n\n\n\n\n3.4 Calculating a single numeric confidence interval using qt()\nUsing qt() is useful if you do not have the raw data, but instead are only given summary statistics.\nTo calculate a confidence interval, we can recall its equation:\n\\[ \\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}} \\]\nMost of those values, namely \\(\\bar{x}, s, n\\), can be found in our summary statistics output:\n\n\n\n  response  min   Q1 median      Q3  max   mean       sd  n missing\n1 Colonies 2301 2504 2616.5 2672.75 2812 2591.3 141.1066 20       0\n\n\n\n3.4.1 From this output identify each value appropriatly:\n\n\n\n\n\nWhat is the value of x-bar?\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the value of \\(s\\)?\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the value of \\(n\\)?\n\n\n\n\n\n\n\n\nSince we know those values, we only need to calculate \\(t^*\\). The t-critical value is calculated using the function qt() using this structure:\n\nqt(1 - alpha/2, df)\n\nThe first entry, is the area to the left of our critical value, if \\(1-\\alpha\\) is our confidence level. qt() will calculate the value of t (t-critical value) that binds that area to the left of it, given your degrees of freedom, \\(df = n-1\\).\nIf we are calculating a 95% confidence interval, then:\n\nthe confidence level \\(1-\\alpha\\) = 0.95, and thus\n\\(\\alpha\\) = 0.05.\n\nSince we know the sample size is 20, then:\n\nthe degrees of freedom (\\(df = n-1\\)) is 19\n\nThus, our code to get the critical value is:\n\n\n\n\n\n\n\n\nWith this value, we can use R to calculate the confidence intervals:\n\n2591.3 + 2.093024*(141.1066/sqrt(20))\n\n[1] 2657.34\n\n2591.3 - 2.093024*(141.1066/sqrt(20))\n\n[1] 2525.26\n\n\nWe can do the same calculation with saved objects, letting us be careful to (1) not round (as those initial outputs may be) and (2) not make a mistake typing values. All we need to do is set each part of our equation as an object value from its direct calculation. The objects xbar, s, n, and crit are made for you. Use those names together to calculate the confidence interval upper bound.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou could take the equation we solved manually and replace the values for the objects that store those value inside them.\n\n\nxbar + crit * (s / sqrt(n))\nxbar + crit * (s / sqrt(n))\n\n\n\n\n\n\nTo finish our confidence interval calculations, we would run the same code but with a ‚Äú-‚Äù instead of a ‚Äú+‚Äù to calculate the lower bound.\n\n\n\n\n\n\n\n\n\n\n\n3.5 Calculating a single numeric confidence interval using t.test()\nIf we have raw data, then we can use the t.test() function to calculate a confidence interval.\nThe structure of the function is as follows:\n\nt.test(~x, data = mydata, conf.level = 1 - alpha)$conf.int\n\nwhere\n\nx is your variable of data for which you want to calculate a confidence interval\nmydata is the name of the dataframe object in R\n\n1-alpha is replaced by your confidence level, in proportions (e.g.: 0.95)\n\nThus, for our 95% confidence interval for our honeybee colony data (recall the variable is Colonies and the dataframe we stored it as is bee), the function would be:\n\n\n\n\n\n\n\n\nThe output supplies first the lower bound (2525.26), then the upper bound (2657.34) and displays your confidence level below again.\nEdit the code below to calculate a 99% confidence interval.\n\n\n\n\n\n\n\n\n\nYou could take the equation we solved manually and replace the values for the objects that store those value inside them.\n\n\nt.test(~Colonies, data = bee, conf.level = 0.99)$conf.int\nt.test(~Colonies, data = bee, conf.level = 0.99)$conf.int\n\n\n\n\n\n\n\n3.5.1 Arrange the words to interpret your confidence interval in the context of the question.\n\n\n\n\n\n\n\nbetween LB and UB\n\n\n\n‚áÖ\n\n\n\nis a single value\n\n\n\n‚áÖ\n\n\n\nBased on the sample\n\n\n\n‚áÖ\n\n\n\nthe true mean number of bee colonies across all weeks in the US since 2000\n\n\n\n‚áÖ\n\n\n\nwe are 95% confident that",
    "crumbs": [
      "Lab Primers",
      "Lab 4 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#introduction",
    "href": "lab-2-primer/lab-2-eda-primer.html#introduction",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Introduction",
    "text": "Introduction\nThis Primer will introduce you to using Markdown to create documents. The good news is: you‚Äôve already been doing this! The .qmd files you are using are Quarto documents that are written with markdown and you‚Äôve been editing them since week 1. We‚Äôre just going to make some of what you‚Äôve already learned more explicit.",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#part-1-introduction-to-markdown",
    "href": "lab-2-primer/lab-2-eda-primer.html#part-1-introduction-to-markdown",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Part 1: Introduction to Markdown",
    "text": "Part 1: Introduction to Markdown\nMarkdown is a way to encode formatting on text in an unobtrusive way (compared to, say, html). Quarto documents use the Markdown language to code the text in the document, and allow you to embed code chunks that execute R code. Your finished .qmd document can be ‚Äòrendered‚Äô to other document types, and the markdown language converts to specific formatting.\nCheck out the markdown and rendered text side-by-side:\n\n\nWhen you do so, you will see this Markdown document converted to an HTML document and **this phrase is now bold**, *this phrase is italicized*, and `this phrase is written to denote R code`. To do the same in your own documents, you can use the same asterisks (*) or back ticks (`) as shown in the unrendered document. \n\n\nWhen you do so, you will see this Markdown document converted to an HTML document and this phrase is now bold, this phrase is italicized, and this phrase is written to denote R code. To do the same in your own documents, you can use the same asterisks (*) or back ticks (`) as shown in the unrendered document.\n\n\nWe are going to learn some of the basic Quarto editing techniques.\n\n1.0 Overview of Quarto\nBefore we continue, check out this Tutorial Hello Quarto (25 min). Remember, you will want to take notes as you move through the tutorials. You can also read more via this optional introduction to Quarto (30 min, all of Chapter 28).\nThe biggest thing to realize is that a Quarto document contains three types of content:\n\nA YAML header surrounded by ---s at the top.\nChunks of R code surrounded by ```{r} and ```.\nText mixed with simple text formatting like # heading and _italics_.\n\nFor our class (STAT 250), you will generally only be editing the Chunks and the Text.\n\n\n1.1. Basic Markdown\nMarkdown can format a document just like you format your Word documents in other classes, but we‚Äôll just cover some of the basics here. You‚Äôve already learned italics, bold and code displays. Markdown can make lists as well, using a variety of encoding (see the online tutorial). You‚Äôve probably also noticed that when you format your text, its color display changes, to help you see the formatting easier.\n\n\nUnrendered\n\n\nRendered\n\n\n\n\n*italics*  or _italics_\n\n\nitalics or italics\n\n\n\n\n**bold**\n\n\nbold\n\n\n\n\n`code`  \n\n\ncode\n\n\n\n\nsubscript~2~    \n\n\nsubscript2\n\n\n\n\nsuperscript^2^  \n\n\nsuperscript2\n\n\n\n\n&gt; Text block for answers\n\n\n\nText block for answers\n\n\n\n\n\n\n# Header Size 1\n\n\nHeader Size 1\n\n\n\n\n## Header Size 2\n\n\nHeader Size 2\n\n\n\n\n\n### Header Size 3\n\n\nHeader Size 3\n\n\n\n\nMarkdown Comments Will Not Render: &lt;!--- this comment won't show up rendered ---&gt;\n\n\nMarkdown Comments Will Not Render: \n\n\nOne last thing of note - markdown works best with ‚Äúspace to breathe.‚Äù If you find that something isn‚Äôt rendering correctly, making sure there is a blank line between the text you are trying to format and the next helps.\n\n\nFor example:\n&gt; Although this is green unrendered, it doesn't appear with the formatting we want. Try adding an \"enter\" between the \"For example:\" and the start of this line and render again. Did it fix it?\nYou'll also notice that if there are no line breaks, this formatting doesn't end, so you don't need to put a \"&gt;\" before each line answer. \n\n\nFor example: &gt; Although this is green unrendered, it doesn‚Äôt appear with the formatting we want. Try adding an ‚Äúenter‚Äù between the ‚ÄúFor example:‚Äù and the start of this line and render again. Did it fix it? You‚Äôll also notice that if there are no line breaks, this formatting doesn‚Äôt end, so you don‚Äôt need to put a ‚Äú&gt;‚Äù before each line answer.\n\n\nNotice what happens when we add spacing:\n\n\nFor example:\n\n&gt; Although this is green unrendered, it doesn't appear with the formatting we want. Try adding an \"enter\" between the \"For example:\" and the start of this line and render again. Did it fix it?\nYou'll also notice that if there are no line breaks, this formatting doesn't end, so you don't need to put a \"&gt;\" before each line answer. \n\n\nFor example:\n\nAlthough this is green unrendered, it doesn‚Äôt appear with the formatting we want. Try adding an ‚Äúenter‚Äù between the ‚ÄúFor example:‚Äù and the start of this line and render again. Did it fix it? You‚Äôll also notice that if there are no line breaks, this formatting doesn‚Äôt end, so you don‚Äôt need to put a ‚Äú&gt;‚Äù before each line answer.\n\n\n\n\n\n1.2. Creating Tables\nThe easiest way to make a table in markdown is using this format:\n\n\nUnrendered\n\n| Right | Left | Default | Center | \n|------:|:-----|---------|:------:| \n|   12  |  12  |    12   |    12  | \n|  123  |  123 |   123   |   123  | \n|    1  |    1 |     1   |     1  | \n\n\nRendered\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\nThe : denotes where the cell values align; default is fine on labs. You might also notice that it doesn‚Äôt mater if my | don‚Äôt line up when we edit a table once we render:\n\n\nUnrendered\n\n| Right | Left | Default | Center | \n|------:|:-----|---------|:------:| \n|   12  |  124 |    12|    12  | \n|  123  |     123 |   123 |   123  | \n|    1  |  176 |     1   |     1  | \n\n\nRendered\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n124\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n176\n1\n1\n\n\n\n\n\nThat said, it is easier to read in the .qmd file if you add spaces and dashes as needed so that they all do line up.\n\n\n1.3. Mathematics\nWe often want to write small mathematics equations or write mathematical symbols. This is actually much easier in .qmd than in Word.\nWe surround an equation with $ signs: $e=mc^2$ which will appear as \\(e=mc^2\\) in the rendered document.\nHere are some examples of the type of mathematics you will use within your Quarto documents.\n\nGreek Letters\nWe often want to use statistical symbols within markdown to denote parameters with Greek letters. They are called by using a backslash (\\) and then the full name of the Greek letter, such as \\alpha, and surrounded by $ to be called within the equation-mode:\n\n\n$\\sigma$\n$\\alpha$\n$\\mu$\n$\\beta$\n\n\n\\(\\sigma\\)\n\\(\\alpha\\)\n\\(\\mu\\)\n\\(\\beta\\)\n\n\n\n\nSuperscripts and Subscripts\nWe can include sub- and superscripts to make our parameters and statistics specific. Note: once the equation is surrounded by $‚Äôs we don‚Äôt need the markdown edit for superscript like above. In math mode, you might see:\n\n\n$x^2$  \n$H_0$  \n$\\mu_1$  \n\n\n\\(x^2\\)\n\\(H_0\\)\n\\(\\mu_1\\)\n\n\nWe might want to make our subscript a longer phrase in statistics, to help denote our population of interest when we have more than one. We surround whatever we want to stay in a subscript with {}, such as:\n\n\n$\\mu_{female}$  \n$\\mu_{male}$ \n\n\n\\(\\mu_{female}\\)\n\\(\\mu_{male}\\)\n\n\n\n\nSymbols over Letters\nWe can call our special statistical symbols in a similar way, such as \\bar{x}. In this case, the bar symbol will be applied over the x, to make our statistical symbol for sample mean: \\(\\bar{x}\\).\n\n\n$\\bar{x}$  \n$\\hat{p}$  \n$\\hat{\\beta}_1$  \n\n\n\\(\\bar{x}\\)\n\\(\\hat{p}\\)\n\\(\\hat{\\beta}_1\\)\n\n\n\n\nEquations\nFinally, we can write little equations for our outputs:, like \\(\\bar{x} = 3.54\\).\n\n\n$\\bar{x} = 3.54$  \n$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$  \n\n\n\\(\\bar{x} = 3.54\\)\n\\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\\)\n\n\n\n\n\n1.4. Code Chunks\nYou‚Äôve learned how to insert code chunks using the shortcuts Ctrl-Alt-I (or Cmd-Alt-I), by clicking the green Insert +C button above, but you can also just type the two sets of code that surround code chunks, ```{r} and the ending ``` . Note, those are back-ticks, found above the tab key, not single quotation marks.\nWe can add labels #| label: to support easy navigation as well, but be careful, DO NOT REPEAT LABELS or this will cause an error when you render the .qmd file.\n\n```{r}\n#| label: simple-addition\n1 + 1\n```\n\n[1] 2\n\n\nAt the beginning of each Quarto document there should be a special code chunk called the setup chunk. This is where we read the packages used in the rest of the document. We often use #| include: false to as an option in the setup code chunk to hide the output in the rendered document.\n\n```{r}\n#| label: setup\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(ggformula)\n```\n\nYou can also comment your code, which is a way of annotating it without affecting the code, using a # followed by text.\n\n```{r}\n#| label: print-answer\n42*42  #the Answer to the Ultimate Question of Life, the Universe, and Everything, Squared\n```\n\n[1] 1764\n\n\n\n\n1.5 In-line code\nOne of the neat features in Quarto files is the ability to combine code chunks, text, and automatically include (or not‚Äì but we always will in this class) code and outputs in the finished document. We‚Äôve been writing code in the code chunks, but you can also write it directly in line with the text using some specific formatting.\nLet‚Äôs demonstrate with our small study dataset. First, we need to read in the data as an object.\n\n```{r}\n#| label: read-study-data\nstudy &lt;- read_csv(\"study.csv\", show_col_types = FALSE) #stops some extra output\n```\n\nThen we could calculate the mean:\n\n```{r}\n#| label: mean-wk1\nmean(~wk1, data = study)\n```\n\n[1] 1.142857\n\n\nBy running the code as above, we calculated the mean, but didn‚Äôt save it as an object ‚Äì it just prints to screen and is forgotten by R. If we save the output as an object, we can use it within the Quarto file. When you save an output to an object name, it will not print the value to the screen unless you tell R to provide the value.\n\n```{r}\n#| label: mean-wk1-assigned\nmwk1 &lt;- mean(~wk1, data = study) # calculates mean and saves it as mwk1\nmwk1 # prints to screen the value saved to the object name\n```\n\n[1] 1.142857\n\n\nWe can use the named objects to display the value stored within it in-line with our text by using the format:r. We already know that paired back-ticks mark text to be printed out in code font. By including the r in the front, we tell it what follows is actual code to be run.\nFor example:\n\n\nThe mean number of hours studied in week 1 is `r mwk1` hours.\n\n\nThe mean number of hours studied in week 1 is 1.1428571 hours.\n\n\nUsing a stored object name is useful if you are going to use the value often (to cut down on typing), but if you only need to use the value small number of times, you can also write the code directly in line. For example:\n\n\nThe maximum number of hours studied in week two is `r max(~wk2, data = study)` hours\n\n\nthe maximum number of hours studied in week two is 5 hours\n\n\nNotice that we never ran that code in any code chunk. It was run and displayed completely in-line.\n\n\n1.6. Checking code & Rendering your Document\nYou can run specific code chunks to check their output by pressing the green play button to run the specific code chunk, or the icon next to it to run all code chunks prior to that code chunk.\n\nViewing Your Rendered Document\nIf you want to check your Markdown editing, you can render the document and view it in the ‚ÄòViewer‚Äô Pane by pressing the ‚ÄòRender‚Äô button at the top of the Quarto document pane. Make sure the setting (gear icon above) is set to ‚ÄòPreview in Viewer pane‚Äô.\n\n\nChanging the Document Type\nYou can change the document type you knit to automatically by changing the output type in the YAML header from format: html to format: docx and press the ‚ÄòRender‚Äô button. Your word document will be created in the project folder! (In this class, we will always use html documents; please don‚Äôt edit the YAML header of your labs; we showed you this simply for future information.)\n---\ntitle: \"My report\"\nformat: html\nexecute:\n  echo: true\n  error: false\n---  \n\n\nErrors in your Code\nIf there is an error in your file, it will not render. When .qmd files render, they run on a completely clean environment. So if you somehow loaded data or something else not with code in your .qmd file, the rendering process will create an error.\nIf you cannot figure out the error, you can generally still get your document to render by changing error: false to error: true in the YAML code at the top.\n---\ntitle: \"My report\"\nformat: html\nexecute:\n  echo: true\n  error: true\n---  \nThis will print out any errors in your code chunks, but still render the document.\n\n\nErrors in your Markdown\nThe most common errors in your markdown that can cause issues are deleting back ticks (`) around your code chunks or dashes (-) from around the YAML code, so always check that first.",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#header-size-2",
    "href": "lab-2-primer/lab-2-eda-primer.html#header-size-2",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Header Size 2",
    "text": "Header Size 2",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#part-2-r-code-exploratory-data-analysis-for-single-numeric-variables",
    "href": "lab-2-primer/lab-2-eda-primer.html#part-2-r-code-exploratory-data-analysis-for-single-numeric-variables",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Part 2: R Code: Exploratory Data Analysis for Single Numeric Variables",
    "text": "Part 2: R Code: Exploratory Data Analysis for Single Numeric Variables\nHere is a review of some of the code you will use in the rest of Lab 2.\nRemember to first run the set up chunks first and check that all necessary packages are loaded.\n\n\n\n\n\n\n\n\n\n2.1 Reading in Data\nNext, we must be sure to read in the data AND assign it to an object name so that we can call it later in other functions.\n\n\n\n\n\n\n\n\nRead the output and add the argument to the function above to ‚Äúquiet this message‚Äù.\n\n\n2.2 Histograms\nHistograms are a great way to explore the distribution (shape, center, spread, outliers) of a variable. Here is the basic structure for a histogram of body mass of the penguins. Add the following arguments.\n\na x-axis label that says \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\"\n\na y-axis label that say \"Number of Penguins\"\nmodify the bin width to 200\nadd the argument color = \"black\" to outline the bars\n\n\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~ body_mass_g, \n             data = penguins,\n             xlab = \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\",\n             ylab = \"Number of Penguins\",\n             binwidth = 200,\n             color = \"black\")\ngf_histogram(~ body_mass_g, \n             data = penguins,\n             xlab = \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\",\n             ylab = \"Number of Penguins\",\n             binwidth = 200,\n             color = \"black\")\n\n\n\n\n\n\n\n\n2.3 Boxplots\nBoxplots are a great way to explore the distribution (shape, center, spread, outliers) of a variable, though they do not give us information about modality. Here is the basic structure for a boxplot of body mass of the penguins. Add the following arguments.\n\na x-axis label that says \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\"\n\n\n\n\n\n\n\n\n\n\n\n\ngf_boxplot(~ body_mass_g, \n           data = penguins,\n           xlab = \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\")\ngf_boxplot(~ body_mass_g, \n           data = penguins,\n           xlab = \"Body Mass (g) of Three Penguin Species in the Palmer Archipelago\")\n\n\n\n\n\n\nIf you want to make a boxplot that compares a variable across groups, you can either use the formula structure:\n\nnumeric_variable ~ group_variable\ngroup_variable ~ numeric_variable\n\nTry switching the order of the two variables below and see what changes.\n\n\n\n\n\n\n\n\n\n\n2.4 Summary Statistics\nThere are a lot of functions we learned for summary statistics, including:\n\nmean()\nmedian()\nsd()\nvar()\nIQR()\nmax()\nmin()\n\nRemember to include na.rm = TRUE if you have missing data to avoid getting NA as your answer.\nCalculate the mean for body mass for penguins.\n\n\n\n\n\n\n\n\n\n\n\nmean(~ body_mass_g, data = penguins, na.rm = TRUE)\nmean(~ body_mass_g, data = penguins, na.rm = TRUE)\n\n\n\n\n\n\nYou can also calculate the mean, or other statistics, split across multiple groups, such as species. Try replacing sd() with other functions.\nRemember to add na.rm = TRUE if you get NA as an output.\n\n\n\n\n\n\n\n\nThere are also some ways to generate multiple different statistics at once. Try the following two codes and note what information they provide.\nWhat information does df_stats provide?\n\n\n\n\n\n\n\n\nWhat information does quantile() provide?",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#help-understanding-the-basal-metabolic-rate-for-bivalves",
    "href": "lab-2-primer/lab-2-eda-primer.html#help-understanding-the-basal-metabolic-rate-for-bivalves",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Help Understanding the Basal Metabolic Rate for Bivalves",
    "text": "Help Understanding the Basal Metabolic Rate for Bivalves\nIn the first question you are given the abstract from the following paper:\nMetabolic rates, climate and macroevolution: a case study using Neogene molluscs\nHere are some tips for critically reading the abstract:\nPrior to Reading\n\nWhat do I know about this topic?\nWhat do I think I will learn about this topic?\nAfter reading the title, what do I think this reading will be about?\n\nDuring Reading\n\nDo I understand what I just read? Look up any words you do not understand.\nDoes it make sense?\nDo I have a clear picture in my head about this information?\nWhat more can I do to understand this?\n\nAfter Reading\n\nWhat were the most important points in this reading?\nWhat new information did I learn?\nHow does it fit in with what I already know?\nShould I go back and reread any part of this material so I can better understand it?",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-2-primer/lab-2-eda-primer.html#final-reminders",
    "href": "lab-2-primer/lab-2-eda-primer.html#final-reminders",
    "title": "Lab 2: Introduction to Quarto Primer",
    "section": "Final Reminders",
    "text": "Final Reminders\nRemember, all the code needed for the labs can be found in your course notebook, through the chapter, in the ‚ÄúHow to do it in R‚Äù section at the end of each chapter, or in the appendix of the notebook.\nPlease see Canvas for information on the Math/Stat Cafe, the CLC Supplemental Instruction and Drop-in Hours, and your Instructor‚Äôs Student Hours (Office Hours) if you need any additional help.",
    "crumbs": [
      "Lab Primers",
      "Lab 2 Primer"
    ]
  },
  {
    "objectID": "lab-10-primer/lab-10-regression-primer.html#getting-started",
    "href": "lab-10-primer/lab-10-regression-primer.html#getting-started",
    "title": "Lab 10: Regression Analysis",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 10 Primer"
    ]
  },
  {
    "objectID": "lab-10-primer/lab-10-regression-primer.html#muscle-mass",
    "href": "lab-10-primer/lab-10-regression-primer.html#muscle-mass",
    "title": "Lab 10: Regression Analysis",
    "section": "2 Muscle Mass",
    "text": "2 Muscle Mass\nA person‚Äôs muscle mass is expected to decrease with age. To explore this relationship in women, a nutritionist randomly selected 60 women between 40 and 79 years old. The research objective is to see if there is the expected muscle mass (in kilograms; kg) linear decrease with respect to age (in years) as an approximate trend. The data are found in the file muscle-mass.csv.\nData from Applied Linear Statistical Models, Kutner et al 2004, 5th ed.\nLet‚Äôs analyze the data using a linear model. We use the following notation for a linear model:\n\\[Y_{muscle~mass} = \\beta_0 + \\beta_1 \\cdot X_{age} + \\epsilon\\]\nFirst, read in the data and look at the variables\n\n\n\n\n\n\n\n\nRecall from Lab 9 Primer you have already evaluated the basics of the linear model (scatterplot, correlation, slope, intercept, and \\(R^2\\)). Here we will focus on determining if there is a decline in muscle mass in women over the age of 40, as age increases\n\n2.1 Create the Model\nModify the code below to estimate the population regression line between muscle mass and age.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint: Creating a Linear Model\n\n\n\n\n\nUse the lm() function to create the model.\n\n\n\n\n\n2.2 Identify the symbolic hypotheses for this study.\n\n2.2.1 Null Hypothesis\n\n\n\n\nŒ≤‚ÇÄ = 0\n\n\nŒ≤‚ÇÅ = 0\n\n\nŒ≤‚ÇÅ = -1.19\n\n\nŒ≤‚ÇÅ &gt; 0\n\n\nŒ≤‚ÇÅ &lt; 0\n\n\nŒ≤‚ÇÅ ‚â† 0\n\n\n\n\n\n\n\n\n\n2.2.2 Alternative Hypothesis\n\n\n\n\nŒ≤‚ÇÄ = 0\n\n\nŒ≤‚ÇÅ = 0\n\n\nŒ≤‚ÇÅ = -1.19\n\n\nŒ≤‚ÇÅ &gt; 0\n\n\nŒ≤‚ÇÅ &lt; 0\n\n\nŒ≤‚ÇÅ ‚â† 0\n\n\n\n\n\n\n\n\nBe sure you can also write the hypotheses verbally in context. Bring your answers to office hours or the CLC for review.\n\n\n\n\n2.3 Evaluate the Conditions of the Test\nConduct the appropriate evaluations for the conditions of regression analysis. Modify the code below to create the additional plots needed.\n\n2.3.1 Linearity\n\n\n\n\n\n\n\n\n\n\n\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\")\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\")\n\n\n\n\n\n\n\n\n2.3.2 QQ Plot of the Residuals\n\n\n\n\n\n\n\n\n\n\n\nplot(mm_age, 2)\nplot(mm_age, 2)\n\n\n\n\n\n\n\n\n2.3.3 Residual vs.¬†Fitted Plot\n\n\n\n\n\n\n\n\n\n\n\nplot(mm_age, 1, add.smooth = TRUE)\nplot(mm_age, 1, add.smooth = TRUE)\n\n\n\n\n\n\n\n\n2.3.4 Cook‚Äôs Distance Plot\n\n\n\n\n\n\n\n\n\n\n\nplot(mm_age, 5, add.smooth = TRUE)\nplot(mm_age, 5, add.smooth = TRUE)\n\n\n\n\n\n\n\n\n\n2.4 Which of the conditions appear to be reasonably met?\n\n\n\n\nLinearity\n\n\nNormality of residuals\n\n\nEqual variance of residuals\n\n\nIndependence of Residuals\n\n\nNo influential points\n\n\n\n\n\n\n\n\nWrite justifications for each condition. Bring your answers to office hours or the CLC for review.\n\n\n\n2.5 Create a Summary Table\nModify the code below the create a summary table to assess whether there is a statistically meaningful relationship between the two variables.\n\n\n\n\n\n\n\n\n\n\n\nsummary(mm_age)\nsummary(mm_age)\n\n\n\n\n\n\n\n\n2.6 Estimate the True Slope\nModify the code below to determine the 95% confidence interval for the slope of the regression line.\n\n\n\n\n\n\n\n\n\n\n\nconfint(mm_age, parm = 2, level = 0.95)\nconfint(mm_age, parm = 2, level = 0.95)\n\n\n\n\n\n\n\nBe sure you can interpret and evaluate the confidence interval. Bring your answers to office hours or the CLC for review.\n\n\n\n2.7 Which of the following statements are true?\n\n\n\n\nThe individuals were sampled randomly, so it implies an observational study\n\n\nThe individuals were not randomly assigned to their value of the explanatory variable, so this is not an experiment but an observational study instead, so we can't determine causality\n\n\nThe individuals were randomly assigned to the explanatory variable, so this is an experiment, so we can say any changes we observed is due to the explanatory variable\n\n\nThe individuals were randomly assigned to the explanatory variable, so this is an experiment, but we can only determine an association, not causality\n\n\nThe individuals were randomly assigned to their value of the explanatory variable, but we cannot generalize to all individuals in the population since there was not also a random selection\n\n\nThe individuals were randomly selected, so we can generalize to the population.",
    "crumbs": [
      "Lab Primers",
      "Lab 10 Primer"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 320 Lab Primers",
    "section": "",
    "text": "This website provides lab primers to practice the code used in STAT 320: Non Parametric Statistics at California State University, Monterey Bay. It uses the following packages:\n\nggformula\n\nmosaic\n\ntidyverse\n\nstats",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "instructions/common-errors.html",
    "href": "instructions/common-errors.html",
    "title": "common-errors",
    "section": "",
    "text": "One of the most frustrating parts for people learning R is troubleshooting errors. R is incredibly powerful, but it is dumb. It can‚Äôt guess what you meant, nor add in a comma that you forgot to type. Read Chapter 6: Deciphering Common R Errors (5 min) which covers the most common errors in R and how to decipher them. R errors aren‚Äôt always clear to new users, but they almost always will direct you to where the problem occurs. Sometimes that is just telling you that it can‚Äôt find the file or object you are trying to point it to. Other times, it will repeat your code right up to the point where it didn‚Äôt understand. That helps focus your attention when searching for errors.",
    "crumbs": [
      "General Lab Instructions",
      "Common Errors"
    ]
  },
  {
    "objectID": "instructions/common-errors.html#part-4-r-grammer-errors",
    "href": "instructions/common-errors.html#part-4-r-grammer-errors",
    "title": "common-errors",
    "section": "",
    "text": "One of the most frustrating parts for people learning R is troubleshooting errors. R is incredibly powerful, but it is dumb. It can‚Äôt guess what you meant, nor add in a comma that you forgot to type. Read Chapter 6: Deciphering Common R Errors (5 min) which covers the most common errors in R and how to decipher them. R errors aren‚Äôt always clear to new users, but they almost always will direct you to where the problem occurs. Sometimes that is just telling you that it can‚Äôt find the file or object you are trying to point it to. Other times, it will repeat your code right up to the point where it didn‚Äôt understand. That helps focus your attention when searching for errors.",
    "crumbs": [
      "General Lab Instructions",
      "Common Errors"
    ]
  },
  {
    "objectID": "lab-1-primer/lab-1-intro-r-primer.html#introduction",
    "href": "lab-1-primer/lab-1-intro-r-primer.html#introduction",
    "title": "Lab 1: Introduction to R Primer",
    "section": "Introduction",
    "text": "Introduction\nDid it increase? Did it decrease? Is it different? Was it successful? Did it achieve the goal? Are these things related? What might we expect?\nThese are common questions for which you could imagine wanting an answer. The ‚Äòit‚Äô might change, depending on any particular job, but the ultimate questions remain the same, and they all are answered with statistics. While statistics used to be done by hand using long and sometimes complicated formulas, statistics are largely (and thankfully!) calculated by computers now and, more and more often, in fields in research, non-profits, government and industry, they are calculated using the program R.\nRecall your earlier reading ‚ÄúWhy R?‚Äù to remember all the reasons we will be learning R in this course. You might feel intimidated at first using a program that takes code, rather than a series of drop-down menus, but we‚Äôll walk through learning the basics of R so that when you leave the class you have a good grasp of R on which to continue building.",
    "crumbs": [
      "Lab Primers",
      "Lab 1 Primer"
    ]
  },
  {
    "objectID": "lab-1-primer/lab-1-intro-r-primer.html#part-1-r-orientation",
    "href": "lab-1-primer/lab-1-intro-r-primer.html#part-1-r-orientation",
    "title": "Lab 1: Introduction to R Primer",
    "section": "Part 1: R Orientation",
    "text": "Part 1: R Orientation\nYou have gotten a quick orientation to R in class. If you need a refresher, read, watch and follow along with Chapter 3.4: RStudio Layout (12 min) in your own RStudio window to understand the use of different panes. You only need to read the entirety (including subsections) of Chapter 3.4, not the entire chapter 3. Don‚Äôt feel like you need to understand all of the coding at this point, just get a sense of what each pane does.\nNow that we have an overview of R, lets get started using R! Don‚Äôt forget to start by first opening the lab project!",
    "crumbs": [
      "Lab Primers",
      "Lab 1 Primer"
    ]
  },
  {
    "objectID": "lab-1-primer/lab-1-intro-r-primer.html#part-2-data-organization",
    "href": "lab-1-primer/lab-1-intro-r-primer.html#part-2-data-organization",
    "title": "Lab 1: Introduction to R Primer",
    "section": "Part 2: Data Organization",
    "text": "Part 2: Data Organization\nOne of the key parts of statistical analyses is good organization of your data itself and your files.\nYou should always work in a project in R to help organize all the files associated with that particular project.\nR expects data to be organized in a particular way to calculate and manipulate your raw data into statistics. Read Data and Presentations (5 min) regarding how data tables need to be arranged for statistical analyses (Tabular and Tidy).",
    "crumbs": [
      "Lab Primers",
      "Lab 1 Primer"
    ]
  },
  {
    "objectID": "lab-1-primer/lab-1-intro-r-primer.html#part-3-r-coding",
    "href": "lab-1-primer/lab-1-intro-r-primer.html#part-3-r-coding",
    "title": "Lab 1: Introduction to R Primer",
    "section": "Part 3: R Coding",
    "text": "Part 3: R Coding\nR, at its most basic, can be thought of as the most powerful calculator you‚Äôve ever had. R isn‚Äôt powerful just from its calculation ability, but its ability to utilize functions to apply complex mathematical operations to whole sets of data, which is what we‚Äôre going to learn.\nLet‚Äôs take a closer look at R commands. Complete the following primer: RStudio Primer: Programming Basics (25 min). (One additional note: the chapter gives some indication of the rules around object names, but doesn‚Äôt include one last rule: object names can‚Äôt have spaces!\n\n3.1 Loading Packages\nR comes with what is called a ‚ÄúBase‚Äù package, which contains numerous functions. There are tens of thousands of additional packages that contain even more packages for everything from 3-D visualizations to machine learning algorithms. To use functions from other packages you must first install the package\n\ninstall.packages(c(\"ggformula\", \"mosaic\", \"tidyverse\"))\n\nInstallation only needs to happen once. If you are using the CSUMB Cal ICOR Server then the above packages are already installed and do not need to be installed again.\nLoading packages must happen each session. We should always load our packages first thing. Go ahead and run the following code to load our needed packages.\n\n\n\n\n\n\n\n\n\n\n3.2: R Syntax\nAs you covered in class, the R language has its own set of grammatical rules. The good news is that once you‚Äôve learned the basic R structure, it is easy to apply to new commands.\nTo get R (or any software) to do anything, there are two important questions you must be able to answer: 1) What do you want R to do, and 2) What must R know to do that?\nThe answers to those questions can help us fill in the boxes of our generic formula template:\n\n\n\nFigure 1: Generic Goal Template\n\n\nQ. What do you want R to do?\nA. goal\n\nThis determines the function to use.\nFunctions carry out commands from their inputs and create an output; in other words, we apply a function to its inputs to create the output.\nFor a plot, the function will describe what sorts of marks to draw (points, in our example). A function could also describe the type of calculation or descriptive statistic.\n\nQ. What must R know to do that?\nA. arguments\n\nThe inputs in R are called arguments.\nFor a plot or statistic calculation, we must identify the variables and the data frame that contains them.\n\nThe application of a function to arguments follows a simple structure: the name of a function is followed by a pair of parentheses. Values for the arguments are specified inside the parentheses. If there is more than one argument, the arguments are always separated by a comma.\nIn the generic function above, goal is the name of any function. The arguments (formula & mydata) identify the variables and dataframe that contains them. The ... indicates any additional arguments we many want to include.\nGenerally, functions are written as the name of the function followed by parentheses, e.g.¬†log(). The empty parentheses are merely a reminder that the name refers to a function.\nSometimes, functions need more than one argument. R functions require the first argument supplied to them to be something specific, but then arguments can be added as needed ‚Äì those additional arguments need to be named so that R knows exactly what you are trying to specify. Named arguments always have the form:\n\n\n\nFigure 2: Generic Argument Syntax\n\n\nThose arguments are added as needed in place of the ... in our template (Fig 3). We can include as many arguments as needed as long as we separate each one with a comma.\n\n\n\nFigure 3: Adding Arguments into Functions Syntax\n\n\n\nFormula Template\nThe formula argument in our template is where we define the variable of data to which we want to apply our goal. There are actually a few options for what that variable can look like, depending on the variables we wish to use. We use y to designate our y-axis variable, x to designate our x-axis variable (or in the second case, one single variable), and z to designate a conditioning variable that lets us create separate panels when we group data. The |z can also be applied to the single variable ~x.\n\n\n\nFigure 1: Generic Goal Template\n\n\n\n\nAssembling the pieces\nNow we need to put together the pieces we‚Äôve learned with our actual scenario. For example, we might keep a record of the number of hours spent studying on each day of the week during week 1 and during week 2 of the semester. We want to make a graphic of the hours spent studying on each day of the week. In this case, we have two variables: hours and day, so we‚Äôll use the template:\n\n\n\nFigure 4: All Possible Generic Function Syntax\n\n\nSo let‚Äôs identify the pieces.\n\n\n\nbox\nfill in with\npurpose\n\n\n\n\ngoal\ngf_col\nplot bars of values\n\n\ny\nhours\ny-axis variable\n\n\nx\nday\nx-axis variable\n\n\nmydata\nstudy2\nname of the dataset\n\n\n\nWe need to fill in each piece into our template. So our code goal (y ~ x , data = mydata) becomes gf_col(hours ~ day, data = study2) and creates the following plot:\n\ngf_col(hours ~ day, data = study2, \n       ylab = \"Hours spent studying in week 1 and week 2\", \n       xlab = \"Day of the week\")\n\n\n\n\n\n\n\n\nLearning any new software can feel daunting, but referring back to this template and asking yourself the two questions ‚Äì what do I want R to do? what must R know to do that? ‚Äì will help you throughout your time working with R.\n\n\n\n3.3: Vectors, Objects, & Dataframes\nThe real power of R comes not from calculating values like a calculator, but in manipulating sets of data. Vectors are sets of data that are organized together. Groups of vectors that are associated are dataframes.\nFor example, we could load version of our data on hours spent studying in week 1 and week 2 that has three columns, one for day and one for each week.\n\n\n# A tibble: 7 √ó 3\n  day     wk1   wk2\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 M         1     2\n2 T         1     4\n3 W         2     5\n4 R         2     4\n5 F         0     0\n6 Sa        1     3\n7 Su        1     3\n\n\nTo be able to work with the dataframe in R, we need to read the csv file into R, using read_csv() which comes from the tidyverse package. We apply that function to the name of the csv file we wish to load, inside quotation marks. Go ahead and run the following code.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nError: could not find function \"read_csv\"\n\n\n\n\n\nIf you get the error could not find function \"read_csv\" be sure you ran the code in Section 3.1.\n\n\n\nThat is okay, but that code alone means that R reads it and then immediately forgets it. If you tried this, your data wouldn‚Äôt appear in your ‚ÄúEnvironment‚Äù pane. We need R to remember and store the information in its active memory.\nWe can store information in R to use again later as an object. An object is a name given to a set of information in R. It can hold dataframes, vectors, numbers, or outputs from commands. To store information, we have to use an assignment operator, &lt;-. Anything on the right of the assignment operator is stored as the name on the left of the assignment operators.\n\n\n\nFigure 5: Generic Stored Object and Assignment Syntax*\n\n\nNames of objects in R can be almost anything, as long as it doesn‚Äôt start with a number, doesn‚Äôt contain a mathematical operator (*, /, ^, etc.) and doesn‚Äôt contain a space. It is also good practice not to name objects the same as function names.\nThus, my code now becomes the following (run it and see what happens!).\n\n\n\n\n\n\n\n\nYou won‚Äôt see the data, just some information about the data, but if you were to look at the Environment pane, a new object would have appeared in RStudio.\n\n\n\nFigure 6: Environment Pane\n\n\nWe can look at all the data within these vectors again by typing the object name into the line of code without any other function. Doing so will print the dataframe to your screen as an output. Go ahead and run the code.\n\n\n\n\n\n\n\n\nSometimes we don‚Äôt want to see all the data, as there are hundreds of data points. We may just want to see the first few lines of data to get a feel for how it is entered. In that case, we can use the function head() to see the first 6 lines of cases:\n\n\n\n\n\n\n\n\nOur vectors are embedded within an object. To access them, we need to direct R first to the dataframe object, then to the variable object. We do so using one of two structures, depending on the function. We also need to know the names our variables are called. We can find out the names our variables are called by using the code names()\n\n\n\n\n\n\n\n\nThe first you have already seen in our template ‚Äì we identify the dataframe using an argument. We can then apply functions to specific variables within our dataframe, such as finding the mean number of hours studied in week 1:\n\n\n\n\n\n\n\n\nor the total number of hours studied across week 1:\n\n\n\n\n\n\n\n\nSome functions don‚Äôt accept the data argument. In those cases, we identify the dataframe and variable using the structure: DATAFRAME$VARIABLE. We can then find the total number of rows in study using the function length()\n\n\n\n\n\n\n\n\nYou will notice that mean() and sum() calculated a single value across the vector. Other functions/operations are vectorized functions - they will apply to each element within the vector and return a vector as the output.\nFor example, if instead of the total number of hours studied across the week, we wanted to know the total number of hours studied on each day of the week, between weeks. We can‚Äôt use sum() because it collapses the information of the days of the week. We can instead add our vectors together:\n\n\n\n\n\n\n\n\nYou will notice that the output of this is to return a vector. Each element of the vector was created by adding the same element of each variable. For example, the first value, 3, was obtained by adding the number of hours studied on Monday of week 1 (1) with the number of hours studied on Monday of week 2 (2), for a total of 3 hours studied on Monday across the two weeks.\nA few other useful functions can help us understand the dataset we loaded into R. ncol() lets us determine the number of variables in the dataset. nrow() lets us determine the number of rows (sometimes the same as cases) in the dataset.",
    "crumbs": [
      "Lab Primers",
      "Lab 1 Primer"
    ]
  },
  {
    "objectID": "lab-1-primer/lab-1-intro-r-primer.html#part-4-r-grammer-errors",
    "href": "lab-1-primer/lab-1-intro-r-primer.html#part-4-r-grammer-errors",
    "title": "Lab 1: Introduction to R Primer",
    "section": "Part 4: R Grammer & Errors",
    "text": "Part 4: R Grammer & Errors\nOne of the most frustrating parts for people learning R is troubleshooting errors. R is incredibly powerful, but it is dumb. It can‚Äôt guess what you meant, nor add in a comma that you forgot to type. Read Chapter 6: Deciphering Common R Errors (5 min) which covers the most common errors in R and how to decipher them. R errors aren‚Äôt always clear to new users, but they almost always will direct you to where the problem occurs. Sometimes that is just telling you that it can‚Äôt find the file or object you are trying to point it to. Other times, it will repeat your code right up to the point where it didn‚Äôt understand. That helps focus your attention when searching for errors.",
    "crumbs": [
      "Lab Primers",
      "Lab 1 Primer"
    ]
  },
  {
    "objectID": "lab-11-primer/lab-11-categorical-primer.html#getting-started",
    "href": "lab-11-primer/lab-11-categorical-primer.html#getting-started",
    "title": "Lab 11: Categorical Data Analysis",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 11 Primer"
    ]
  },
  {
    "objectID": "lab-11-primer/lab-11-categorical-primer.html#hair-and-eye-color",
    "href": "lab-11-primer/lab-11-categorical-primer.html#hair-and-eye-color",
    "title": "Lab 11: Categorical Data Analysis",
    "section": "2 Hair and Eye Color",
    "text": "2 Hair and Eye Color\nIn 1974 a Statistics professor collected data on 592 randomly selected students at the University of Delaware to help the students learn about analysis of categorical data. Import the data eye-hair-color.csv.\n\n\n\n\n\n\n\n\n\n\n2.1 Exploratory Data Analysis\nHere are the summary statistics and data visualizations we can create for categorical data.\n\n2.1.1 Calculate Frequency/Count\nWe can use the tally() function to find the counts/frequency of the hair and eye color of the individuals in the study.\n\ntally(~x , data = mydata)\n\nHere is the frequency distribution for hair color in our sample.\n\n\n\n\n\n\n\n\nCalculate the frequency distribution of eye color in the sample:\n\n\n\n\n\n\n\n\n\n\n\ntally(~Eye, data = eye_hair)\ntally(~Eye, data = eye_hair)\n\n\n\n\n\n\n\n\n2.1.2 Calculate Relative Frequency/Proportion\nWe can adjust the arguments in the tally() function to find the proportion/relative frequency of the hair and eye color of the individuals in the study.\n\ntally(~x , data = mydata, format = \"prop\")\n\nHere is the relative frequency distribution for hair color in our sample.\n\n\n\n\n\n\n\n\nCalculate the relative frequency distribution of eye color in the data:\n\n\n\n\n\n\n\n\n\n\n\ntally(~Eye, data = eye_hair, format = \"prop\")\ntally(~Eye, data = eye_hair, format = \"prop\")\n\n\n\n\n\n\n\n\n2.1.3 Creating a Contingency Table\nSuppose we want to compare the distribution of eye color across different hair colors. We can create a contingency table using the same tally() function.\n\ntally(y ~ x , data = mydata) #y position are rows, x position are columns\n\nHere is the frequency distribution for hair and eye color in our sample.\n\n\n\n\n\n\n\n\n\n\n2.1.4 Calculate Conditional Proportions\nIn order to calculate the conditional proportions, we can adjust our code a little bit to make it clear which variable we are conditioning on.\n\ntally(~y | x , data = mydata, format = \"prop\") # y conditioned on x\n\nHere are the conditional proportions of hair color given eye color in our sample.\n\n\n\n\n\n\n\n\nNow calculate the conditional proportions of eye color given hair color:\n\n\n\n\n\n\n\n\n\n\n\ntally(~ Eye | Hair, data = eye_hair, format = \"prop\")\ntally(~ Eye | Hair, data = eye_hair, format = \"prop\")\n\n\n\n\n\n\n\n\n2.1.5 Bar Plots of Counts\nWe can choose from several options for our bar plot for a single categorical variable.\n\ngf_bar(~x , data = mydata)\n\nHere is the bar plot for hair color counts in our sample.\n\n\n\n\n\n\n\n\nCreate a bar plot for the eye color counts in the our sample:\n\n\n\n\n\n\n\n\n\n\n\ngf_bar(~Eye, data = eye_hair, \n       xlab = \"Color of Eye\",\n       ylab = \"Number of Statistics Students at Univ. of Del. in 1974\")\ngf_bar(~Eye, data = eye_hair, \n       xlab = \"Color of Eye\",\n       ylab = \"Number of Statistics Students at Univ. of Del. in 1974\")\n\n\n\n\n\n\n\n\n2.1.6 Bar Plots of Proportions\nWe can choose from several options for our bar plot for a single categorical variable.\n\ngf_props(~x , data = mydata)\n\nHere is the bar plot for hair color proportions in our sample.\n\n\n\n\n\n\n\n\nCreate a bar plot for the eye color counts in the our sample:\n\n\n\n\n\n\n\n\n\n\n\ngf_props(~Eye, data = eye_hair, \n       xlab = \"Color of Eye\",\n       ylab = \"Proportion of Statistics Students at Univ. of Del. in 1974\")\ngf_props(~Eye, data = eye_hair, \n       xlab = \"Color of Eye\",\n       ylab = \"Proportion of Statistics Students at Univ. of Del. in 1974\")\n\n\n\n\n\n\n\n\n2.1.7 Bar Plots of Conditional Proportions\nHere is an example of a plot where we look at the conditional proportion for eye color conditioned on hair color.\n\n\n\n\n\n\n\n\n\nWhat do you notice about how the distribution of eye color varies among those with different hair colors?",
    "crumbs": [
      "Lab Primers",
      "Lab 11 Primer"
    ]
  },
  {
    "objectID": "lab-11-primer/lab-11-categorical-primer.html#comparing-eye-color-distribution-from-1974-and-2025.",
    "href": "lab-11-primer/lab-11-categorical-primer.html#comparing-eye-color-distribution-from-1974-and-2025.",
    "title": "Lab 11: Categorical Data Analysis",
    "section": "3 Comparing Eye Color Distribution from 1974 and 2025.",
    "text": "3 Comparing Eye Color Distribution from 1974 and 2025.\nIn 2025 a study was published using all 50 states‚Äô Department of Motor Vehicles information to identify eye and hair color for all registered individuals. They found the following:\n\n\n\nEye Color\nPercent\n\n\n\n\nBlue\n25%\n\n\nBrown\n55%\n\n\nGreen\n9%\n\n\nHazel\n11%\n\n\n\nWe want to determine if the distribution of eye color of statistics students at the University of Delaware in 1974 is similar the distribution of eye color in the United States in 2025.\n\n3.1 Distribution of Blue Eye Color\nLet‚Äôs first practice with a simple hypothesis test to determine if the true proportion of blue eyes was higher among statistics students at the University of Delaware in 1974 compare to the proportion of blue eyes in the US in 2025.\n\n3.1.1 Null Hypothesis\n\n\n\n\nœÄ = 0\n\n\nœÄ &gt; 0\n\n\nœÄ &lt; 0\n\n\nœÄ ‚â† 0\n\n\nœÄ = 0.237\n\n\nœÄ &gt; 0.237\n\n\nœÄ &lt; 0.237\n\n\nœÄ ‚â† 0.237\n\n\n\n\n\n\n\n\n\n\n3.1.2 Alternative Hypothesis\n\n\n\n\nœÄ = 0\n\n\nœÄ &gt; 0\n\n\nœÄ &lt; 0\n\n\nœÄ ‚â† 0\n\n\nœÄ = 0.237\n\n\nœÄ &gt; 0.237\n\n\nœÄ &lt; 0.237\n\n\nœÄ ‚â† 0.237\n\n\n\n\n\n\n\n\n\nBe sure you can also write the hypotheses verbally in context. Bring your answers to office hours or the CLC for review.\n\n\n\n3.1.3 Calculate the p-value using the Binomial Distribution\nAdjust the code below to calculate the correct p-value for the test using the binomial distribution.\n\n\n\n\n\n\n\n\n\n\n\n1 - pbinom(215 - 1, size = 592, prob = 0.237)\n1 - pbinom(215 - 1, size = 592, prob = 0.237)\n\n\n\n\n\n\n\n\n\n3.2 Evaluate the Chi-Square Goodness-of-Fit\n\n3.2.1 Null Hypothesis\nNow we are going to test the full hypothesis that the true proportions for the eye color for statistics students at the University of Delaware in 1974 match the current distribution of eye colors in the United States in 2025, i.e.\n\\[H_0: \\pi_{blue} = 0.25,~\\pi_{brown} = 0.55,~\\pi_{green} = 0.09,~\\pi_{hazel} = 0.11\\]\n\n\n3.2.2 Alternative Hypothesis\nReorder the values below to write out the verbal alternative hypothesis, using the same order for the expected proportions as listed in the symbolic null hypothesis. Place the population in the last position.\n\n\n\n\n\n\n0.25 for blue eyes,\n\n\n\n‚áÖ\n\n\n\nat least one of the\n\n\n\n‚áÖ\n\n\n\n0.55 for brown eyes,\n\n\n\n‚áÖ\n\n\n\npopulation proportions\n\n\n\n‚áÖ\n\n\n\n0.09 for green eyes,\n\n\n\n‚áÖ\n\n\n\nof eye color\n\n\n\n‚áÖ\n\n\n\nand 0.11 for hazel eyes\n\n\n\n‚áÖ\n\n\n\nis different than the expected values of\n\n\n\n‚áÖ\n\n\n\namong statistics students at the University of Delaware in 1974\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Calculate the p-value\n\n\n\n\n\n\n\n\n\n\n\nxchisq.test(~Eye, data = eye_hair, p = c(0.25, 0.55, 0.09, 0.11))\nxchisq.test(~Eye, data = eye_hair, p = c(0.25, 0.55, 0.09, 0.11))\n\n\n\n\n\n\n\n\n3.2.4 What do we conclude from our test?\n\n\n\n\nno evidence against the null\n\n\nsome evidence against the null\n\n\nmoderate evidence against the null\n\n\nstrong evidence against the null\n\n\nvery strong evidence against the null\n\n\n\n\n\n\n\n\n\n\n\n3.3 Checking Conditions for Goodness-of-Fit Test\nCheck all the conditions we meet in our scenario to determine if we can use the Chi-Square Distribution as a model for the null distribution and trust our calculated p-value.\n\n\n\n\nThe measurements are categorical\n\n\nCategories are mutually exclusive\n\n\nObservations are independent\n\n\nNo category has an expected frequency of less than 5",
    "crumbs": [
      "Lab Primers",
      "Lab 11 Primer"
    ]
  },
  {
    "objectID": "lab-3-primer/lab-3-intro-inference-primer.html#getting-setup",
    "href": "lab-3-primer/lab-3-intro-inference-primer.html#getting-setup",
    "title": "Lab 3: Introduction to Inference Primer",
    "section": "1 Getting Setup",
    "text": "1 Getting Setup\nReminder: Before starting, load the ggformula and mosaic packages we need for statistical and graphical functions using the library() function in the code chunk below. Replace __graphics package__ and __stats package__ with the package names.\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse) #data management\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse) #data management\nlibrary(ggformula)\nlibrary(mosaic)",
    "crumbs": [
      "Lab Primers",
      "Lab 3 Primer"
    ]
  },
  {
    "objectID": "lab-3-primer/lab-3-intro-inference-primer.html#penny-age",
    "href": "lab-3-primer/lab-3-intro-inference-primer.html#penny-age",
    "title": "Lab 3: Introduction to Inference Primer",
    "section": "2 Penny Age",
    "text": "2 Penny Age\nCoins are stamped with the year in which they were minted, and stay in circulation until they are too worn, at which point they are removed from circulation. With the rising cost of raw materials, it is more expensive to manufacture pennies than the coin is worth. Furthermore, as the US moves towards a more cashless society, the use of physical coins is declining, making the penny less necessary. On May 22, 2025, The U.S. Treasury Department announced it would end penny production starting in 2026. We are going to estimate the mean age of all circulating U.S. pennies. Rolls of pennies were collected from a bank in Marina, California in Spring 2020. The data of the age of the penny (in number of years) since 2019 can be found in penny-age-2019.csv.\n\n\n2.1 Import the Data\nComplete the code below to (1) read in the csv file penny-age-2019.csv and store it as the object penny, and (2) print the variable names. Replace the underscored sections of the code with data file name and function.\n\n\n\n\n\n\n\n\nYou can modify the code above to hide the output if you want, by adding show_col_types = FALSE to the function.\n\n\n\n\n\n\n\n\n\n\n\nnames(penny)\nnames(penny)\n\n\n\n\n\n\n\n\n2.2 Visualize the Data\nUse gf_histogram() to create a histogram of the sample distribution, being sure to label axes appropriately. Replace the underscored components. With good labels such as:\n\n\"Age in Years of US Pennies from Marina, CA Bank (Sp 2020)\"\n\"Number of Pennies\"\n\nTry a bin width of 5 years\n\nSet the lower bound of the bars to 0 so it doesn‚Äôt look like we have negative ages.\n\n\n\n\n\n\n\n\n\n\n\n\ngf_histogram(~ age, data = penny,\n             xlab = \"Age in Years of US Pennies from Marina, CA Bank (Sp 2020)\",\n             ylab = \"Number of Pennies\",\n             binwidth = 5,\n             boundary = 0,\n             color = \"black\")\ngf_histogram(~ age, data = penny,\n             xlab = \"Age in Years of US Pennies from Marina, CA Bank (Sp 2020)\",\n             ylab = \"Number of Pennies\",\n             binwidth = 5,\n             boundary = 0,\n             color = \"black\")\n\n\n\n\n\n\n\n2.2.1 Describe the shape of the distribution of penny ages in our sample.\n\n\n\n\nSymmetric\n\n\nSkewed Right\n\n\nSkewed Left\n\n\nUnimodal\n\n\nBimodal\n\n\nUniform\n\n\n\n\n\n\n\n\n\n\n\n2.3 Calculate Summary Statistics\nUse df_stats() to calculate the descriptive statistics. Replace is the underscored components.\n\n\n\n\n\n\n\n\n\n\n\ndf_stats(~ age, data = penny)\ndf_stats(~ age, data = penny)\n\n\n\n\n\n\n\n\n2.4 Check Your Undertanding\n\n2.4.1 What do the following symbols represent? Arrange the descriptions in order.\n\n\\(\\mu\\)\n\n\\(\\bar{x}\\)\n\n\\(s\\)\n\n\\(n\\)\n\n\n\n\n\n\n\nSample Standard Deviation\n\n\n\n‚áÖ\n\n\n\nSample Size\n\n\n\n‚áÖ\n\n\n\nSample Mean\n\n\n\n‚áÖ\n\n\n\nPopulation Mean\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 Identify the population of interest.\n\n\n\n\nall coins\n\n\nall US coins\n\n\nall circulating US pennies\n\n\nall US pennies from the Marina bank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5 Construct a Confidence Interval\nLet‚Äôs use a model to find a 95% confidence interval.\n\nGo to: Confidence Interval Applet\n\nChange the scenario to ‚Äòone mean‚Äô\n\nEnter your sample‚Äôs \\(n\\), \\(\\bar{x}\\), and \\(s\\) into the fields, then ‚Äòcalculate‚Äô\n\nClick ‚ÄúConfidence Interval‚Äù.\n\nEnter the correct confidence level.\n\nClick ‚ÄòCalculate.‚Äô\n\nThe confidence interval and degrees of freedom are displayed.\n\nRecord the calculated confidence interval and degrees of freedom that is returned. Keep all 4 decimal places in your answers.\n\n\n2.5.1 Lower bound:\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Upper bound:\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.3 df:\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.4 Arrange the words to interpret your confidence interval in the context of the question.\n\n\n\n\n\n\n\nis a single value\n\n\n\n‚áÖ\n\n\n\nwe are 95% confident that\n\n\n\n‚áÖ\n\n\n\nthe true mean age of all circulating US pennies\n\n\n\n‚áÖ\n\n\n\nbetween LB and UB\n\n\n\n‚áÖ\n\n\n\nBased on our sample\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.5 What needs to be true in order to generalize to the population of interest?\n\n\n\n\n\nPennies from a bank are a natural random sample from all circulating US Pennies.\n\n\nThe sample size is greater than 30.\n\n\nThe data are symmetric and unimodal.\n\n\n\n\n\n\n\n\n\n\n2.5.6 To use the model (t-distribution) to calculate the confidence interval, a condition/conditions need to be satisfied. Which condition(s) are they?\n\n\n\n\n\nRandom Sample\n\n\nSufficient Sample Size\n\n\nNormality",
    "crumbs": [
      "Lab Primers",
      "Lab 3 Primer"
    ]
  },
  {
    "objectID": "lab-5-primer/lab-5-two-groups-primer.html#getting-started",
    "href": "lab-5-primer/lab-5-two-groups-primer.html#getting-started",
    "title": "Lab 5: Two Group EDA and QQ Plot Primer",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 5 Primer"
    ]
  },
  {
    "objectID": "lab-5-primer/lab-5-two-groups-primer.html#sex-bias-in-professor-ratings",
    "href": "lab-5-primer/lab-5-two-groups-primer.html#sex-bias-in-professor-ratings",
    "title": "Lab 5: Two Group EDA and QQ Plot Primer",
    "section": "2 Sex Bias in Professor Ratings",
    "text": "2 Sex Bias in Professor Ratings\nSex bias stems from a perceived mismatch from an expected role or characteristics based on sex. Studies have shown that men and women have unconscious sex biases against women in traditionally male-dominated fields (such as the sciences) or characteristics (such as leadership qualities). These biases often cause equally qualified women to be seen as less likable or less qualified than the men. (These links are to descriptions of two well-known studies, but there are plenty of other good resources).\nResearchers are interested if this sex bias exists in traditionally female-dominated jobs as well, such as teaching. Students are asked to watch a video of an animated classroom and rate the professor. Each student is randomly assigned to either of two animations; the videos are exactly the same except for the sex of the professor drawn. You have been asked to analyze the data for the researchers to determine if the female-identifying professor is rated more poorly, on a 1 to 7 scale (with 7 being the best), than the male-identifying professor.\nRun the following code chunk to read in the data and view the variable names and first 6 rows of the data.\n\n\n\n\n\n\n\n\n\n2.1 Identify Key Components of the Scenario\n\nFor each variable, identify whether it is the explanatory or response variable in our analysis, and the type of variable.\n\nSex:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\nRating:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentify the study design of this study.\nBe sure you are able to provide a full justification.\n\n\n\n\nIndependent Two Sample\n\n\nMatched Pair Sample\n\n\n\n\n\n\n\n\n\n\nIdentify the study type of this study.\nBe sure you are able to provide a full justification.\n\n\n\n\nExperiment\n\n\nObservational\n\n\n\n\n\n\n\n\n\n\n\n2.2 Exploratory Data Analysis\n\nCalculate the summary statistics for each sample. Modify the code below to calculate the summary statistics for each group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_stats(Rating ~ Sex, data = bias)\nmean(Rating ~ Sex, data = bias)\nvar(Rating ~ Sex, data = bias)\nsd(Rating ~ Sex, data = bias)\ndf_stats(Rating ~ Sex, data = bias)\nmean(Rating ~ Sex, data = bias)\nvar(Rating ~ Sex, data = bias)\nsd(Rating ~ Sex, data = bias)\n\n\n\n\n\n\n\n\n2.2.1 Create a boxplot of the data by modifying the code below.\nRecall that ~, which translates as ‚Äúby‚Äù or ‚Äúas a function of,‚Äù lets us graph one variable split by another. (For a boxplot, a numeric variable split by a categorical variable). Be sure to add fully descriptive axis labels. Note the solution will provide its own labels, but as long as they contain similar information they are good labels!\n\n\n\n\n\n\n\n\n\n\n\ngf_boxplot(Rating ~ Sex, data = bias, \n        ylab = \"Rating of Professor (1-7)\", \n        xlab = \"Sex of the Professor\") \ngf_boxplot(Rating ~ Sex, data = bias, \n        ylab = \"Rating of Professor (1-7)\", \n        xlab = \"Sex of the Professor\") \n\n\n\n\n\n\n\n\n2.2.2 Based on your boxplot,\n\nWhat is the approximate median rating for females?\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the approximate median rating for males?\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich of the following is an appropriate statistic to describe the variability (i.e.¬†dispersion, spread) in rating of male-identifying professors?\n\n\n\n\nsd\n\n\nmedian\n\n\nIQR\n\n\nmean\n\n\n\n\n\n\n\n\n\n\nWhich of the following is an appropriate statistic to describe the variability (i.e.¬†dispersion, spread) in rating of female-identifying professors?\n\n\n\n\nmedian\n\n\nIQR\n\n\nmean\n\n\nsd\n\n\n\n\n\n\n\n   \n\n\n\n\n\n\n2.3 Assessing Normality of the Ratings by Group\nConstruct a Quantile-Quantile Plot (QQ Plot) to evaluate the normality of the data. Remember for two independent groups, you must look at the QQ Plot split by the group (~ y | x ).\n\n\n\n\n\n\n\n\n\n\n\ngf_qq(~Rating | Sex, data = bias,\n      xlab = \"Theoretical Z-Scores\",\n      ylab = \"Ratings of Professors\") |&gt; \n  gf_qqline()\ngf_qq(~Rating | Sex, data = bias,\n      xlab = \"Theoretical Z-Scores\",\n      ylab = \"Ratings of Professors\") |&gt; \n  gf_qqline()\n\n\n\n\n\n\n\n\n2.4 Interpreting QQ Plots\nRemember to completely interpret the QQ Plot,\n\nGeneral Pattern: Discuss the pattern compared to the 1:1 line that represents perfect normality.\nSpecifics: Describe specific details about the pattern such as if there are any deviations, where the deviations are located along the 1:1 line, and the magnitude of the deviations.\nConsideration for n: Evaluate the severity of the deviations from the 1:1 line relative to the sample size, which should be cited.\nCumulative Frequency: Discuss the cumulative frequency rate of increase of the data points/residuals relative to the 1:1 line.\n\n\n2.4.1 Based on the QQ Plot for Female Professors, evaluate the following statements and determine if the are Complete, Incomplete, or Missing.\n\nThe female-identifying scores seem normally distributed as they follow along the line with no apparent outliers.\n\nGeneral Pattern:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nSpecifics:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nConsideration for n:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nCumulative frequency rate of increase:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\n\n\nThe data does not follow the 1:1 line, points start above the line and then end below the line. That means there are more data points, especially on the left tail, than expected. The cumulative frequency increases too quickly.\n\nGeneral Pattern:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nSpecifics:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nConsideration for n:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nCumulative frequency rate of increase:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\n\n\nThe majority of data points in the center of the Female plot are close to the 1:1 line, but deviates at the tails. The sample size is \\(n=34\\) so we can expect variability. This implies that the plot is mostly normally distributed.\n\nGeneral Pattern:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nSpecifics:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nConsideration for n:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nCumulative frequency rate of increase:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\n\n\nThe female plot trends normally with most of the plot points trending relatively close to the 1:1 line. There is only one large deviation in the upper tail. This means the cumulative frequency rate increases.\n\nGeneral Pattern:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nSpecifics:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nConsideration for n:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nCumulative frequency rate of increase:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\n\n\nThe center of each data group is a little skewed and does not follow the 1:1 line. There are deviations apparent, given our sample size of 34. This means that the rate of cumulative frequency increase is not relatively normal.\n\nGeneral Pattern:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nSpecifics:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nConsideration for n:\n\n\n\n\nComplete\nIncomplete\nMissing\n\n\n\n\n\n\n\n\n\nCumulative frequency rate of increase:\n\n\n\n\nComplete\nIncomplete\nMissing",
    "crumbs": [
      "Lab Primers",
      "Lab 5 Primer"
    ]
  },
  {
    "objectID": "lab-5-primer/lab-5-two-groups-primer.html#parents-age-gap",
    "href": "lab-5-primer/lab-5-two-groups-primer.html#parents-age-gap",
    "title": "Lab 5: Two Group EDA and QQ Plot Primer",
    "section": "3 Parents Age Gap",
    "text": "3 Parents Age Gap\nA recent study found the average Homo sapiens father has always been older than the average Homo sapiens mother for 250,000 years. However, the age gap has dwindled in the last 5,000 years, largely due to mothers having children at older ages. With declining teen birth rate, rising birth rates among older women, and women pursuing higher education and careers before starting families, the average age of all mothers giving birth in the United States increased to nearly 30 in 2023. While the age gap between parents can vary greatly, it‚Äôs common for fathers to be just a few years older than mothers.\nThe National Vital Statistics System (NVSS) is a collaborative effort between state and local governments to compile and publish reports on all vital events - births, deaths, marriages, and divorces. A random sample of 50 births in 2022 was extracted from NVSS. The data for mother‚Äôs age and father‚Äôs age can be found in nvss-births-2022.csv.\n\n\n\n\n\n\n\n\n\n3.0.1 For each variable, identify whether it is the explanatory or response variable in our analysis, and the type of variable.\n\nSex:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\nAge:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\nIdentify the study design of this study. Be sure you are able to provide a full justification.\n\n\n\n\nIndependent Two Sample\n\n\nMatched Pair Sample\n\n\n\n\n\n\n\n\n\n\nIdentify the study type of this study. Be sure you are able to provide a full justification.\n\n\n\n\nExperiment\n\n\nObservational\n\n\n\n\n\n\n\n\n\n\n\n3.0.2 Calculate the summary statistics for the differences.\nModify the code below to calculate the summary statistics. We will focus on the difference between the Father‚Äôs age and the Mother‚Äôs age.\n\n\n\n\n\n\n\n\n\n\n\ndf_stats(~(FatherAge - MotherAge), data = parents)\nmean(~(FatherAge - MotherAge), data = parents)\nvar(~(FatherAge - MotherAge), data = parents)\nsd(~(FatherAge - MotherAge), data = parents)\ndf_stats(~(FatherAge - MotherAge), data = parents)\nmean(~(FatherAge - MotherAge), data = parents)\nvar(~(FatherAge - MotherAge), data = parents)\nsd(~(FatherAge - MotherAge), data = parents)\n\n\n\n\n\n\n\n\n3.0.3 Create a boxplot of the differences by modifying the code below.\nBe sure to add fully descriptive axis labels. As long as your axis contains similar information it is fine.\n\n\n\n\n\n\n\n\n\n\n\ngf_boxplot(~(FatherAge - MotherAge), data = parents,\n      xlab = \"Difference between Father's and Mother's Age of Newborn Infants in 2023\") \ngf_boxplot(~(FatherAge - MotherAge), data = parents,\n      xlab = \"Difference between Father's and Mother's Age of Newborn Infants in 2023\") \n\n\n\n\n\n\n\n\n3.1 Assessing Normality of the Differences\nConstruct a Quantile-Quantile Plot (QQ Plot) to evaluate the normality of the differences Remember for two dependent/matched groups, you must look at the QQ Plot of the differences (~ (x1 - x2)).\n\n\n\n\n\n\n\n\n\n\n\ngf_qq(~(FatherAge - MotherAge), data = parents,\n      xlab = \"Theoretical Z-Scores\",\n      ylab = \"Difference between Father's and Mother's Age\") |&gt; \n  gf_qqline()\ngf_qq(~(FatherAge - MotherAge), data = parents,\n      xlab = \"Theoretical Z-Scores\",\n      ylab = \"Difference between Father's and Mother's Age\") |&gt; \n  gf_qqline()\n\n\n\n\n\n\nPractice writing a description of whether or not the differences are normally distributed based on the QQ Plot. (Hint - it is does not meet conditions to be considered normally distributed!),",
    "crumbs": [
      "Lab Primers",
      "Lab 5 Primer"
    ]
  },
  {
    "objectID": "lab-7-primer/lab-7-paired-groups-primer.html#getting-started",
    "href": "lab-7-primer/lab-7-paired-groups-primer.html#getting-started",
    "title": "Lab 7: Hypothesis Testing - Paired Groups",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\n\n\n\n\n\n\n\n\n\n\n\n\nRevisit Lab 5 Primer\n\n\n\nThe examples used in the Lab 6 Primer are continuations from the Lab 5 Primer. We encourage you to go back and review your previous answers and code to help you with your lab.",
    "crumbs": [
      "Lab Primers",
      "Lab 7 Primer"
    ]
  },
  {
    "objectID": "lab-7-primer/lab-7-paired-groups-primer.html#birth-parents-age-gap",
    "href": "lab-7-primer/lab-7-paired-groups-primer.html#birth-parents-age-gap",
    "title": "Lab 7: Hypothesis Testing - Paired Groups",
    "section": "2 Birth Parents Age Gap",
    "text": "2 Birth Parents Age Gap\nA recent study found the average Homo sapiens father has always been older than the average Homo sapiens mother for 250,000 years. However, the age gap has dwindled in the last 5,000 years, largely due to mothers having children at older ages. With declining teen birth rate, rising birth rates among older women, and women pursuing higher education and careers before starting families, the average age of all mothers giving birth in the United States increased to nearly 30 in 2023. While the age gap between parents can vary greatly, it‚Äôs common for fathers to be just a few years older than mothers.\nThe National Vital Statistics System (NVSS) is a collaborative effort between state and local governments in the US to compile and publish reports on all vital events - births, deaths, marriages, and divorces. A random sample of 50 births in 2022 was extracted from NVSS. The data for mother‚Äôs age and father‚Äôs age can be found in nvss-births-2022.csv.\nThe researchers want to determine if the age gap still exists and if fathers are still older than mothers.\nRun the following code chunk to read in the data and view the variable names.\n\n\n\n\n\n\n\n\n\n2.1 Identify the Parameters\n\nIdentify the study design of this study.\nBe sure you are able to provide a full justification. This is review from the Lab 5 Primer.\n\n\n\n\nIndependent Two Sample\n\n\nMatched Pair Sample\n\n\n\n\n\n\n\n\n\n\nIdentify the correct parameter type for this study. Be sure you are able to complete the full parameter in context.\n\n\n\n\nTrue mean difference\n\n\nDifference in true means\n\n\n\n\n\n\n\n\n\n\nIdentify the parameter(s) that would be of interest based on the study design.\n\n\n\n\nŒº‚Çì‚Çì = true mean age in years of mothers\n\n\nŒº‚Çì·µß = true mean age in years of fathers\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì = true mean of the differences of the ages in years of fathers and mothers\n\n\nxÃÑ‚Çì‚Çì\n = mean age in years of mothers in our sample\n\n\nxÃÑ‚Çì·µß\n = mean age in years of fathers in our sample\n\n\nxÃÑ‚Çì·µß‚Çã‚Çì‚Çì = mean of the differences of the ages in years of fathers and mothers in our sample\n\n\n\n\n\n\n\n\n\n\nIdentify the null hypothesis that would be of interest based on the study design.\nThe researchers want to determine if the fathers‚Äô ages are greater than the mothers‚Äô ages at birth.\n\n\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì = 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì &lt; 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì &gt; 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì ‚â† 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì = 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì &lt; 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì &gt; 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì ‚â† 0\n\n\n\n\n\n\n\n\n\n\nIdentify the alternative hypothesis that would be of interest based on the study design.\nThe researchers want to determine if the fathers‚Äô ages are greater than the mothers‚Äô ages at birth.\n\n\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì = 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì &lt; 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì &gt; 0\n\n\nŒº‚Çì·µß - Œº‚Çì‚Çì ‚â† 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì = 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì &lt; 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì &gt; 0\n\n\nŒº‚Çì·µß‚Çã‚Çì‚Çì ‚â† 0\n\n\n\n\n\n\n\n\n\n\n\n2.2 Exploratory Data Analysis\nRecall from the Lab 5 Primer, we calculated the following summary statistics and data visualizations.\n\n2.2.1 Summary Statistics\n\ndf_stats(~(FatherAge - MotherAge), data = parents) \n\n                  response min Q1 median Q3 max mean       sd  n missing\n1 I(FatherAge - MotherAge) -13  0      1  4  17  1.8 4.952839 50       0\n\n\n\n\n2.2.2 Data Visualization\n\ngf_boxplot(~(FatherAge - MotherAge), data = parents,\n           xlab = \"Difference in Ages Between Fathers and Mothers\") |&gt; \n  gf_theme(axis.ticks.y = element_blank(),  #removes y-axis ticks\n           axis.text.y = element_blank())   #removes y-axis labels\n\n\n\n\n\n\n\n\n\n\n2.2.3 QQ Plot\n\ngf_qq(~(FatherAge - MotherAge), data = parents,\n      ylab = \"Difference in Ages Between Fathers and Mothers\",\n      xlab = \"Theoretical Z-Scores\") |&gt; \n  gf_qqline()\n\n\n\n\n\n\n\n\n\nBased on the provided information, do we meet the necessary conditions to conduct inference using the t-distribution (e.g.¬†confidence interval, hypothesis test)?\n\n\n\n\nYes, because we have random sample\n\n\nYes, because our sample size is greater than 30\n\n\nNo, because our sample data is skewed\n\n\n\n\n\n\n\n\nRemember to check the conditions of sufficient sample size and normality together.\n\nThe sufficient sample size depends on whether our sample indicates the population may or may not be normality distributed (now evaluated using the QQ Plot).\n\nProvide a statement, based on the condition check, to determine if we can or cannot use the t-distribution as a model for null distribution or sampling distribution of our test/sample statistic.\n\n\n\n\n\n2.3 Calculating the Test Statistic and P-Value\nWe will practice code for both a ‚Äúby-hand‚Äù calculation and using t.test() (which is what we will be using from in general).\n\nCalculate the summary statistics for each sample. Modify the code below to calculate the summary statistics for each group.\n\n\n\n\n\n\n\n\nYou should get the following values:\n\n\n\n\n\n\n\n\nmean_diff\nsd_diff\nn_diff\neffect_diff\n\n\n\n\n1.8\n4.952839\n50\n0.3634279\n\n\n\n\n\n\n\n\n\n\n2.4 Calculating a t-Test Statistic and p-Value for the Mean of the Differences\nNow that we have the necessary summary statistics saved, we can calculate both our test statistic (t) and our p-value. Recall the t-statistic for an matched pairs test is\n\\[t_0 = \\frac{\\bar{x}_{d} - d_0}{\\frac{s_{d}}{\\sqrt{n_{d}}}}\\]\nFill in the blanks below using the saved object names (e.g.¬†mean_diff, sd_diff) from above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, calculate the p-value using the pt() function. Consider the direction of the alternative hypothesis.\n\n\n\n\n\n\n\n\n\n\n\n1-pt(t, df = n_diff - 1)\n1-pt(t, df = n_diff - 1)\n\n\n\n\n\n\nTest statistic: Round to 4 decimal places.\n\n\n\n\n\n\n\n\n\n\ndf:\n\n\n\n\n\n\n\n\n\n\np-value: Round to 6 decimal places.\n\n\n\n\n\n\n\n\n\n\n\nNow, let‚Äôs calculate the test statistic and p-value using the t.test() function. Consider the direction of the alternative hypothesis. Recall you have three choices for the alternative.\n\n\"two.sided\"\n\n\"greater\"\n\n\"less\"\n\n\n\n\n\n\n\n\n\n\n\n\nt.test(~(FatherAge - MotherAge), data = parents, mu = 0, alternative = \"greater\")\nt.test(~(FatherAge - MotherAge), data = parents, mu = 0, alternative = \"greater\")\n\n\n\n\n\n\n\n2.4.1 Switching the Direction of the Difference\nUltimately, it is up to the researcher to choose the direction of the calculated difference. If we wanted to switch our difference and have Mother‚Äôs Age - Father‚Äôs Age we would have to tell R to change the ordering of inside each of our functions.\nRerun the t.test() code, but calcuate the differences between Mother‚Äôs Age and Father‚Äôs Age instead of the other way around. What do you have to change to make the test equivalent?\n\n\n\n\n\n\n\n\n\n\n\nt.test(~(MotherAge - FatherAge), data = parents, mu = 0, alternative = \"less\")\nt.test(~(MotherAge - FatherAge), data = parents, mu = 0, alternative = \"less\")\n\n\n\n\n\n\n\n\n\n2.5 Interpreting and Evaluating the p-Value\nUsing the calculate p-value from the t.test() function to answer the following questions. (Use the original ordering of Father‚Äôs Age - Mother‚Äôs Age).\n\nWhich of the following are correct interpretations of a p-value?\n\n\n\n\nThe probability of observing our test statistic\n\n\nThe probability of observing our test statistic or greater\n\n\nThe probability of observing our test statistic or greater, assuming the null hypothesis is true\n\n\nThe probability of observing our test statistic or greater, assuming the alternative hypothesis is true\n\n\nThe probability that the null hypothesis is true\n\n\nThe probability that the alternative hypothesis is true\n\n\nThe probability that we find evidence against the null hypothesis\n\n\n\n\n\n\n\n\n\n\nEvaluate the strength of evidence against the null hypothesis, using a significance level of \\(\\alpha = 0.05\\)\n\n\n\n\nno evidence\n\n\nlittle evidence\n\n\nsome evidence\n\n\nmoderate evidence\n\n\nstrong evidence\n\n\nvery strong evidence\n\n\n\n\n\n\n\n\n\n\n\n\n\nFull Evaluation of Strength of Evidence\n\n\n\n\n\nRemember we have specific details to include in a full evaluation of the strength of evidence.\nWe have {very strong/strong/moderate/some/little} evidence against the null hypothesis (in favor of the alternative hypothesis) that {context of indicated hypothesis} (t = {xxx}, df = {xxx}, p-value = {xxx}).\n\n\n\n\n\n\nWhich of the following statements are true based on the p-value?\n\n\n\n\nthere is a very small probability the null is true\n\n\nour data/test statistic is very unlikely to be observed if the null is true\n\n\nthere is a very small probability the alternative is true\n\n\nthere is a very large probability the alternative is true\n\n\nthere is a very small probability of finding evidence against the null\n\n\n\n\n\n\n\n\n\n\nWhich of the following are possible, given the results of the hypothesis test?\n\n\n\n\nOur result is a Type I Error\n\n\nOur result is a Type II Error\n\n\nOur result is Correct\n\n\n\n\n\n\n\n\n\n\nWhich is the best definintion of Power in the context of the study?\n\n\n\n\nThe probability of finding no evidence of a difference in the age of parents, when there is a difference\n\n\nThe probability of finding no evidence of a difference in the age of parents, when there is no difference\n\n\nThe probability of finding evidence of a difference in the age of parents, when there is a difference\n\n\nThe probability of finding evidence of a difference in the age of parents, when there is no difference\n\n\n\n\n\n\n\n\n\n\n\n2.6 Calculating a Confidence Interval for the Mean of the Differences\nIn order to calculate the confidence interval for the population mean of the differences, it takes on the same structure as a confidence interval for one population mean.\n\\[point \\ estimate \\pm (critical \\ value)*(standard\\ error)\\]\nor\n\\[\\bar{x}_d \\ \\pm \\ t^*\\frac{s_d}{\\sqrt{n_d}}\\]\nWe can find our \\(t^*\\) critical value the same way we found it for previous confidence intervals.\n\n\n\n\n\n\n\n\nOur point estimate is \\(\\bar{x}_d\\)\n\n\n\n\n\n\n\n\nand finally we can calculate the lower bound (lb) and upper bound (ub) for our confidence interval.\n\n\n\n\n\n\n\n\nRecord the calculated confidence interval.\nLower bound:\n\n\n\n\n\n\n\n\n\n\nUpper bound:\n\n\n\n\n\n\n\n\n\n\n\nOf course, the ‚Äúby-hand‚Äù method is tedious when we can just use t.test() to calculate our confidence interval. Fill in the blanks below to calculate the 95% confidence interval for the difference between the two means.\n\n\n\n\n\n\n\n\n\n\n\nt.test(~(FatherAge - MotherAge), data = parents, conf.level = 0.95)$conf.int\nt.test(~(FatherAge - MotherAge), data = parents, conf.level = 0.95)$conf.int\n\n\n\n\n\n\n\n\nProvide an interpretation of the confidence interval by reordering the phrases below.\n\n\n\n\n\n\nof the differences between\n\n\n\n‚áÖ\n\n\n\nthe age of mothers\n\n\n\n‚áÖ\n\n\n\nthe age of fathers\n\n\n\n‚áÖ\n\n\n\nLB and UB\n\n\n\n‚áÖ\n\n\n\nand\n\n\n\n‚áÖ\n\n\n\nthe true mean\n\n\n\n‚áÖ\n\n\n\nwe are 95% confident that\n\n\n\n‚áÖ\n\n\n\nBased on the sample\n\n\n\n‚áÖ\n\n\n\nis a single value\n\n\n\n‚áÖ\n\n\n\nwithin the interval\n\n\n\n\n\n\n\n\n\n\n\n\nWhich of the following would be plausible estimates for the true mean of the differences between fathers‚Äô and mothers‚Äô ages?\n\n\n\n\n0\n\n\n-1\n\n\n1\n\n\n-1.5\n\n\n-0.5\n\n\n0.5\n\n\n1.5\n\n\n-2\n\n\n2\n\n\n\n\n\n\n\n\n\n\nWhat can we conclude about the study?\n\n\n\n\nwe cannot infer that the age of the mother causes the age of the father to be higher\n\n\nwe can infer that the age of the mother causes the age of the father to be higher\n\n\nthere is evidence that fathers tend to be older than mothers in 2022\n\n\nthere is no that fathers tend to be older than mothers in 2022\n\n\nthe effect size indicates a large difference between the ages of fathers and mothers\n\n\nthe effect size does not indicate a large difference between the ages of fathers and mothers\n\n\n\n\n\n\n\n\n\n\nIndentify the population to which you can generalize.\n\n\n\n\nall Homo sapiens\n\n\nall birth parents\n\n\nall US birth parents\n\n\nall US birth parents in 2022\n\n\nall parents with an age gap\n\n\nnone",
    "crumbs": [
      "Lab Primers",
      "Lab 7 Primer"
    ]
  },
  {
    "objectID": "lab-9-primer/lab-9-eda-two-variable-primer.html#getting-started",
    "href": "lab-9-primer/lab-9-eda-two-variable-primer.html#getting-started",
    "title": "Lab 9: Correlation and Linear Models",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nBe sure to load the packages ggformula and mosaic, using the library() function. Remember, you need to do this with each new Quarto document or R Session. Add the package names in each of the blanks below to load in the indicated packages.\n\n\n\n\n\n\n\n\n\nlibrary() loads in packages. You need to supply the package name you need to load inside the parentheses.\n\n\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management\nlibrary(ggformula) #for graphs\nlibrary(mosaic) #for statistics\nlibrary(tidyverse) #for data management",
    "crumbs": [
      "Lab Primers",
      "Lab 9 Primer"
    ]
  },
  {
    "objectID": "lab-9-primer/lab-9-eda-two-variable-primer.html#muscle-mass",
    "href": "lab-9-primer/lab-9-eda-two-variable-primer.html#muscle-mass",
    "title": "Lab 9: Correlation and Linear Models",
    "section": "2 Muscle Mass",
    "text": "2 Muscle Mass\nA person‚Äôs muscle mass is expected to decrease with age. To explore this relationship in women, a nutritionist randomly selected 60 women between 40 and 79 years old. The research objective is to see if there is the expected muscle mass (in kilograms; kg) linear decrease with respect to age (in years) as an approximate trend. The data are found in the file muscle-mass.csv.\nData from Applied Linear Statistical Models, Kutner et al 2004, 5th ed.\nLet‚Äôs analyze the data using a linear model. We use the following notation for a linear model:\n\\[Y_{muscle~mass} = \\beta_0 + \\beta_1 \\cdot X_{age} + \\epsilon\\]\nFirst, read in the data and look at the variables.\n\n\n\n\n\n\n\n\n\n2.0.1 For each variable, identify whether it is the explanatory or response variable in our analysis, and the type of variable.\n\nAge:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\nMuscle Mass:\n\n\n\n\nExplanatory\n\n\nResponse\n\n\nCategorical\n\n\nNumeric\n\n\n\n\n\n\n\n\n\n\n\n2.0.2 Identify the study type of this study. Be sure you are able to provide a full justification.\n\n\n\n\nExperiment\n\n\nObservational",
    "crumbs": [
      "Lab Primers",
      "Lab 9 Primer"
    ]
  },
  {
    "objectID": "lab-9-primer/lab-9-eda-two-variable-primer.html#exploratory-data-analysis",
    "href": "lab-9-primer/lab-9-eda-two-variable-primer.html#exploratory-data-analysis",
    "title": "Lab 9: Correlation and Linear Models",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\nConduct Exploratory Data Analysis (EDA). Modify the code below to calculate any summary statistics and produce a graphic appropriate for assessing relationships between two variables.\n\n\n\n\n\n\n\n\n\n\n\ncor(muscle_mass ~ age, data = muscle)\ncor(muscle_mass ~ age, data = muscle)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\")\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\")\n\n\n\n\n\n\n\n3.0.1 Based on the Correlation and Scatterplot, select the best descriptions of the relationship between age of females and muscle mass.\n\n\n\n\nStrong\n\n\nWeak\n\n\nLinear\n\n\nNonlinear\n\n\nNegative\n\n\nPositive",
    "crumbs": [
      "Lab Primers",
      "Lab 9 Primer"
    ]
  },
  {
    "objectID": "lab-9-primer/lab-9-eda-two-variable-primer.html#constructing-the-linear-model",
    "href": "lab-9-primer/lab-9-eda-two-variable-primer.html#constructing-the-linear-model",
    "title": "Lab 9: Correlation and Linear Models",
    "section": "4 Constructing the Linear Model",
    "text": "4 Constructing the Linear Model\nNow let‚Äôs fit a least squares regression line to our data, using the form\n\\[\\hat{y}_{muscle~mass} = b_0 + b_1x_{age}\\]\n\n4.1 Modify your code above to add a linear model to the plot.\n\n\n\n\n\n\n\n\n\n\n\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\") |&gt; \n  gf_lm()\ngf_point(muscle_mass ~ age, data = muscle,\n           ylab = \"Muscle Mass (kg)\",\n           xlab = \"Age (in years) of Female Participants\") |&gt; \n  gf_lm()\n\n\n\n\n\n\n\n\n4.2 Modify the code below to estimate the population regression line using the data and find the slope and intercept.\nHint: use the functions lm() and coef()\n\n\n\n\n\n\n\n\n\n4.2.1 Intercept:\nRound to 2 decimal places\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.2 Choose the correct interpretation of the intercept from the options below.\nThe [intercept] would be replaced with the value calculated above.\n\n\n\n\nWhen age is 0 years, the muscle mass of women is expected to be [intercept] kg.\n\n\nWhen age is 0 years, the muscle mass of women is [intercept] kg.\n\n\nWhen muscle mass is 0 kg, the age of women is expected to be [intercept] years.\n\n\nWhen muscle mass is 0 kg, the age of women is [intercept] years.\n\n\n\n\n\n\n\n\n\n\n4.2.3 Slope:\nRound to 2 decimal places\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.4 Choose the correct interpretation of the slope from the options below.\nThe [slope] would be replaced with the value calculated above.\n\n\n\n\nAs age increases by 1 year, the muscle mass of women between the ages of 40-79 years will decrease by the [slope] kg.\n\n\nAs age increases by 1 year, the muscle mass of women between the ages of 40-79 years is expected to decrease by the [slope] kg.\n\n\nAs muscle mass increases by 1 kg, the age of women between the ages of 40-79 years is expected to decrease by [slope] years.\n\n\nAs age increases, the muscle mass of women between the ages of 40-79 years decreases.\n\n\n\n\n\n\n\n\n\n\n\n4.3 Modify the code below the create a summary table to assess whether there is a statistically meaningful relationship between the two variables. Then determine the following statistics for your linear model.\n\n\n\n\n\n\n\n\n\n\n\nsummary(mm_age)\nsummary(mm_age)\n\n\n\n\n\n\n\n4.3.1 \\(R^2\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Just \\(R^2\\)\n\n\n\n\n\nIf you wanted to just print out the \\(R^2\\) value in R, you could use the following code:\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Arrange the words to interpret the coefficient of determination. \\(R^2\\) is‚Ä¶\n\n\n\n\n\n\nby the linear model\n\n\n\n‚áÖ\n\n\n\nwith age\n\n\n\n‚áÖ\n\n\n\nin women aged 40-79 years old\n\n\n\n‚áÖ\n\n\n\nthat is explained\n\n\n\n‚áÖ\n\n\n\nthe proportion of variability\n\n\n\n‚áÖ\n\n\n\nin muscle mass",
    "crumbs": [
      "Lab Primers",
      "Lab 9 Primer"
    ]
  },
  {
    "objectID": "lab-9-primer/lab-9-eda-two-variable-primer.html#calculations-using-the-linear-model",
    "href": "lab-9-primer/lab-9-eda-two-variable-primer.html#calculations-using-the-linear-model",
    "title": "Lab 9: Correlation and Linear Models",
    "section": "5 Calculations using the Linear Model",
    "text": "5 Calculations using the Linear Model\nNow that you have the linear model you can calculate the specific values to either\n\nEstimate the mean muscle mass for a particular age\n\nPredict the muscle mass for an individual of a particular age\n\n\n5.1 Calculate the average muscle mass of 60 year old women.\n\n\n\n\n\n\n\n\n\n\n\n156.35 + -1.19*60\n156.35 + -1.19*60\n\n\n\n\n\n\n\n\n\n\n\n\nUsing R to Make Predictions\n\n\n\n\n\nIf you wanted to save yourself some hand calculations, you could use the predict() function in R. You just provide newdata and it will calculate a prediction for the provided value.",
    "crumbs": [
      "Lab Primers",
      "Lab 9 Primer"
    ]
  },
  {
    "objectID": "prep-materials/intro-to-quarto.html",
    "href": "prep-materials/intro-to-quarto.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "The theme of this lesson is good management of your files and data. In part two of this week‚Äôs coursework you will learn how to identify folders and paths, and create Quarto documents.",
    "crumbs": [
      "Getting Started with R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "prep-materials/intro-to-quarto.html#file-management",
    "href": "prep-materials/intro-to-quarto.html#file-management",
    "title": "Introduction to Quarto",
    "section": "File Management",
    "text": "File Management\nAs boring as it sounds, file management is arguably one of the most important skills a data scientist should have. The reproducibility of a project depends just as much on the way in which the project was stored as the computing tools used. While using R and Quarto make an important step in creating a reproducible analysis, there are other pieces that are arguably just as important‚Äîsuch as file management.\nBelieve it or not, your computer has multiple locations** where files can be stored. There has been a bit of a generational shift as computers have evolved: the ‚Äúfile system‚Äù metaphor itself is outdated because no one uses physical files anymore.\n[This article]((https://futurism.com/the-byte/gen-z-kids-file-systems) makes the argument that with modern search capabilities, most people use their computers as a laundry hamper instead of as a nice, organized filing cabinet. However, the laundry hamper approach doesn‚Äôt play nicely with working in R and creating Quarto documents.\nA good programmer will store files according to the Project TIER protocol. More specifically, you will have:\n\na ‚ÄúStat 250‚Äù folder in your Documents folder, containing all your materials associated with STAT 250\na sub-folder for each week (e.g., Week 1, Week 2)\nseparate folders within each week for each assignment (e.g., Practice Activity, Lab)",
    "crumbs": [
      "Getting Started with R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "prep-materials/intro-to-quarto.html#introduction-to-quarto",
    "href": "prep-materials/intro-to-quarto.html#introduction-to-quarto",
    "title": "Introduction to Quarto",
    "section": "Introduction to Quarto",
    "text": "Introduction to Quarto\n\nüìñ Recommended Reading: Intro to Quarto\n\n\nHTML Documents\nWe will exclusively use HTML documents in this course. If you are interested in learning more about formatting options for Quarto HTML documents, I would recommend checking out:\n\na discussion of the basics of formatting HTML documents in Quarto\nthe list of all HTML Formatting options for Quarto documents\n\n\n\nGetting in the Details of Quarto\nThe following video goes into the details about the ways to adopt and work with Quarto documents to produce reproducible analyses.",
    "crumbs": [
      "Getting Started with R",
      "Introduction to Quarto"
    ]
  },
  {
    "objectID": "instructions/importing-exporting.html",
    "href": "instructions/importing-exporting.html",
    "title": "Setting up and Finishing your Lab",
    "section": "",
    "text": "This video shows a general lab workflow that you will follow, except for their instructions for turning in a .zip. You will instead download ONLY the rendered .html file and submit that to your assignment.\nTo submit your .html, be sure you first: * Set up to view rendered document in the Viewer Pane (only need to set once; instructions in video) * Check the .qmd was renamed with your ‚ÄúLastF-‚Äù prior to the file name * Check the .qmd is the correct one to submit with all your work (if you renamed this when you imported it initially, then there shouldn‚Äôt be any confusions) * Render the .qmd to .html fresh prior to exporting, so you don‚Äôt accidentally submit an old .html.\n\n\nNote: if you cannot render your document, there are instructions in the video to how to force a render.",
    "crumbs": [
      "General Lab Instructions",
      "Lab Workflow"
    ]
  },
  {
    "objectID": "instructions/importing-exporting.html#lab-workflow",
    "href": "instructions/importing-exporting.html#lab-workflow",
    "title": "Setting up and Finishing your Lab",
    "section": "",
    "text": "This video shows a general lab workflow that you will follow, except for their instructions for turning in a .zip. You will instead download ONLY the rendered .html file and submit that to your assignment.\nTo submit your .html, be sure you first: * Set up to view rendered document in the Viewer Pane (only need to set once; instructions in video) * Check the .qmd was renamed with your ‚ÄúLastF-‚Äù prior to the file name * Check the .qmd is the correct one to submit with all your work (if you renamed this when you imported it initially, then there shouldn‚Äôt be any confusions) * Render the .qmd to .html fresh prior to exporting, so you don‚Äôt accidentally submit an old .html.\n\n\nNote: if you cannot render your document, there are instructions in the video to how to force a render.",
    "crumbs": [
      "General Lab Instructions",
      "Lab Workflow"
    ]
  }
]